---
title: "Hydra Chronicles Part V: Loose Ends"
author: ~
date: '2019-08-22'
slug: hydra-loose-ends
categories: [r]
tags: [group-stats,optim,hydra]
image:
  /post/2019-07-26-hydra-loose-ends_files/user-imgs/loose-ends-square.png
imagerect:
  /post/2019-07-26-hydra-loose-ends_files/user-imgs/loose-ends-rect.png
imagemrgvt: 0%
imagemrghz: 0%
weight: 1
contenttype: article
description: "A few more tricks for fast group statistics in base R, and
benchmarks against C implementations."
---



<STYLE type='text/css' scoped>
PRE.fansi SPAN {padding-top: .25em; padding-bottom: .25em};
</STYLE>
<div id="almost-done" class="section level1">
<h1>Almost Done!</h1>
<!-- this needs to become a shortcode -->
<p><img
  id='front-img'
  src='/post/2019-07-26-hydra-loose-ends_files/user-imgs/loose-ends-square.png'
  class='post-inset-image'
/></p>
<p>Fingers crossed this will be the last post of the <a href="/tags/hydra/">Hydra Chronicles</a>, a.k.a.
“Everything You Didn’t Want To Know About Group Statistics But Let Me Tell You
Anyway”. Well, it’s more of a salvage job of tidbits from earlier posts that
ended up on the cutting room floor that I couldn’t quite bring myself to trash.</p>
<p>One of our early “discoveries” about group statistics is that if we can compute
the group sum quickly, we can use it to compute many other group statistics
quickly as well. In this post we’ll go over a few of the other group sum
strategies I tested out before I settled on the <a href="/2019/06/10/base-vs-data-table/#group-sums"><code>cumsum</code> based approach</a>
we used to “beat” <code>data.table</code>.</p>
</div>
<div id="rowsum" class="section level1">
<h1>rowsum</h1>
<p>I did mention this one <a href="/2019/06/10/base-vs-data-table/#rowsums">in passing</a>, but it bears re-examining:
<code>base::rowsum</code> is a remarkable creature in the R. As far as I know, it is the
only base R function that computes group statistics on unequal group sizes in
statically compiled code. Despite this it is arcane, especially when compared
with its popular cousin <code>base::rowSums</code>.</p>
<p><code>rowsum</code> and <code>rowSums</code> are near indistinguishable on name alone, but they
do quite different things. <code>rowsum</code> collapses rows together by group, leaving
column count unchanged, whereas <code>rowSums</code> collapses all columns leaving row
count unchanged:</p>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/rowsum-vs-rowsum-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In the single column/vector case, <code>rowsum(x, grp)</code> computes the sum of <code>x</code> by
the groups in <code>grp</code>. Typically this operation is done with <code>tapply(x, grp, sum)</code> (or <code>vapply(split(x, grp), sum, 0)</code>):</p>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/rowsum-vs-tapply-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>As illustrated above <code>tapply</code> must split the vector by group, explicitly call
the R-level <code>sum</code> on each group, and simplify the result to a
vector<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. <code>rowsum</code> can just compute the group sums directly in
statically compiled code. This makes it substantially faster, although
obviously limits it to computing sums.</p>
<p>Let’s look at some examples and timings with our beaten-to-death 10MM row, ~1MM
group <a href="#data">data set</a>, and our timing function <a href="#sys-time"><code>sys.time</code></a>. We’ll
order the data first as <a href="/2019/05/17/pixie-dust/">that is fastest</a> even when including the time to
order:</p>
<pre class="r"><code>sys.time({
  o &lt;- order(grp)
  go &lt;- grp[o]
  xo &lt;- x[o]
})</code></pre>
<pre><code>   user  system elapsed
  0.690   0.003   0.696</code></pre>
<p><code>tapply</code> for reference:</p>
<pre class="r"><code>sys.time(gsum.0 &lt;- tapply(xo, go, sum))</code></pre>
<pre><code>   user  system elapsed
  2.273   0.105   2.383</code></pre>
<p>And now <code>rowsum</code>:</p>
<pre class="r"><code>sys.time(gsum.1 &lt;- rowsum(xo, go))</code></pre>
<pre><code>   user  system elapsed
  0.507   0.038   0.546</code></pre>
<pre class="r"><code>all.equal(c(gsum.0), c(gsum.1), check.attributes=FALSE)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>This is a ~4-5x speedup for the summing step, or a ~3x speedup if we include the
time to order. <code>data.table</code> is faster for this task.</p>
<blockquote>
<p>All <code>data.table</code> timings are single threaded (<code>setDTthreads(1)</code>)<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
</blockquote>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/group-sum-times-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The slow step for <code>data.table</code> is also the ordering, but we don’t have a
good way to break that out.</p>
</div>
<div id="colsums" class="section level1">
<h1>colSums</h1>
<p><code>base::rowSums</code>, the aforementioned better-known cousin of <code>rowsum</code>, also
computes group statistics with statically compiled code. Well, it kind of does
if you consider matrix rows to be groups. <code>base::colSums</code> does the same except
for columns. Suppose we have three equal sized ordered groups:</p>
<pre class="r"><code>(G &lt;- rep(1:3, each=2))</code></pre>
<pre><code>[1] 1 1 2 2 3 3</code></pre>
<p>And values that belong to them:</p>
<pre class="r"><code>set.seed(1)
(a &lt;- runif(6))</code></pre>
<pre><code>[1] 0.266 0.372 0.573 0.908 0.202 0.898</code></pre>
<p>We can compute the group sums using <code>colSums</code> by wrapping our vector into a
matrix with as many columns as there are groups. Since R internally stores
matrices as vectors in column-major order, this is a natural operation (and also
why we use <code>colSums</code> instead of <code>rowSums</code>):</p>
<pre class="r"><code>(a.mx &lt;- matrix(a, ncol=length(unique(G))))</code></pre>
<pre><code>      [,1]  [,2]  [,3]
[1,] 0.266 0.573 0.202
[2,] 0.372 0.908 0.898</code></pre>
<pre class="r"><code>colSums(a.mx)</code></pre>
<pre><code>[1] 0.638 1.481 1.100</code></pre>
<p>This is equivalent to<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>:</p>
<pre class="r"><code>c(rowsum(a, G))</code></pre>
<pre><code>[1] 0.638 1.481 1.100</code></pre>
<p>We run into problems as soon as we have uneven group lengths, but there is a
workaround. The idea is to use clever indexing to embed the values associated
with each group into columns of a matrix. We illustrate this process with a
vector with 95 elements in ten groups. For display purposes we wrap the vector
column-wise every ten elements, and designate the groups by a color. The values
of the vector are represented by the tile heights:</p>
<!--
For how we built the 3D animation see:

static/post/2019-07-26-hydra-loose-ends_files/scripts/threed-plot.R
-->
<div id="flipbook1">

</div>
<!--
  Flipbook HTML template, intended to be copied for use in actual instantiated 
  flipbooks
-->
<div id='bg-flipbook-template' style='display: none;'>
<div id="bg-flipbook-images" style="display: none">

</div>
<div style="margin: auto; display: block; width: 95%;">
<canvas id="bg-flipbook-flipbook" style="width: 100%; display: block;" title="Click to step forward, shift+click to step backwards.">
This is an HTML Canvas flipbook that displays key frames of an animation in a
more controllable manner than in a video player. If you are reading this text
your browser does not support HTML Canvas.
</canvas>
<p style="margin-top: 5px; margin-bottom: 25px;">
<input
      id='bg-flipbook-help' type='button' value='?' style='font-size: 18px;'
      title='Display help overlay'
    />
<input
      id='bg-flipbook-play' type='button' value='&#x25b6;' style='font-size: 18px;'
      title='Play/Pause'
    />
<input
      id='bg-flipbook-stop' type='button' value='&#x25a0;' style='font-size: 18px;'
      title='Stop and Reset'
    />
 
<input
      id='bg-flipbook-step-b' type='button' value='&#10703;' style='font-size: 18px;'
      title='Step Backwards'
    />
<input
      id='bg-flipbook-step-f' type='button' value='&#10704;' style='font-size: 18px;'
      title='Step Forwards'
    />
 
FPS:
<input
      id='bg-flipbook-fps' type='text'
      style='width: 3ex; font-size: 18px; text-align: right; min-height: 0;
      line-height: 1; padding: 0;'
      title='Set Playback Rate' value=3
    />
 
Frame:
<input
      id='bg-flipbook-frame'
      type='text'
      style='width: 2.5ex; font-size: 18px; text-align: right; min-height: 0;
      line-height: 1; padding: 0;'
      value=1
      title='Jump to frame #'
    /> / <span id="bg-flipbook-frame-n"></span>
</p>
</div>
<script type='text/javascript' src='/script/_lib/flipbook/flipbook.js'></script>
<script type='text/javascript'>
var img_dir = '/post/2019-07-26-hydra-loose-ends_files/user-imgs/flip-book/';
var fps_def = 1;
var img_n = 15;
var end_delay = 1;
new BgFlipBook('flipbook1', img_dir, img_n, 1, fps_def, end_delay);
</script>
<p>You can also view the flipbook <a href="/post/2019-07-26-hydra-loose-ends_files/scripts/anim.html">as a video</a> if you prefer.</p>
<p>The embedding step warrants additional explanation. The trick is to generate a
vector that maps the positions from our irregular vector into the regular
matrix. There are several ways we can do this, but the one that we’ll use today
takes advantage of the underlying vector nature of matrices. In particular, we
will index into our matrices as if they were vectors, e.g.:</p>
<pre class="r"><code>(b &lt;- 1:4)</code></pre>
<pre><code>[1] 1 2 3 4</code></pre>
<pre class="r"><code>(b.mx &lt;- matrix(b, nrow=2))</code></pre>
<pre><code>     [,1] [,2]
[1,]    1    3
[2,]    2    4</code></pre>
<pre class="r"><code>b[3]</code></pre>
<pre><code>[1] 3</code></pre>
<pre class="r"><code>b.mx[1, 2]   # matrix indexing</code></pre>
<pre><code>[1] 3</code></pre>
<pre class="r"><code>b.mx[3]      # vector indexing on matrix</code></pre>
<pre><code>[1] 3</code></pre>
<p>Let’s look at our 95 data before and after embedding, showing the indices in
vector format for both our ordered vector (left) and the target matrix (right):</p>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/index-compare-1.png" width="1280.16" style="display: block; margin: auto;" /></p>
<p>The indices corresponding to each group diverge after the first group due
to the unused elements of the embedding matrix, shown in grey above. What we’re
looking for is a fast way to generate the indices in the colored cells in the
matrix on the right. In other words, we want to generate the <code>id1</code> (<code>id.embed</code>
in the animation) vector below. For clarity we only show it for the first three
groups:</p>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/pad-index-1.png" width="672" style="display: block; margin: auto;" />
We can emphasize the relationship between these by looking at the element by
element difference in each index vector, e.g. using <code>diff</code>:<span id="diff-id1"></span></p>
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/pad-index-diff-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The indices always increment by one, except at group transitions for the
embedding indices as shown in green above. There they increment by <code>$1 + pad$</code>.
“<code>$pad$</code>” is how much empty space there is between the end of the group and the
end of the column it is embedded in. The name of the game is to compute
“<code>$pad$</code>”, which thankfully we can easily do by using the output of <code>rle</code>:</p>
<pre class="r"><code>g.rle &lt;- rle(sort(g))
g.rle</code></pre>
<pre><code>Run Length Encoding
  lengths: int [1:10] 8 7 7 6 8 13 14 7 11 14
  values : int [1:10] 1 2 3 4 5 6 7 8 9 10</code></pre>
<p><code>rle</code> gives us the length of runs of repeated values, which in our sorted group
vector gives us the size of each group. Padding is then the difference between
each group’s size and that of the largest group:</p>
<pre class="r"><code>g.max &lt;- max(g.rle[[&#39;lengths&#39;]])      # largest group
(pad &lt;- g.max - g.rle[[&#39;lengths&#39;]])</code></pre>
<pre><code> [1] 6 7 7 8 6 1 0 7 3 0</code></pre>
<p>To compute the embedding vector we start by a vector of the differences which
as a baseline are all 1:</p>
<pre class="r"><code>id0 &lt;- rep(1L, length(g))</code></pre>
<p>We then add the padding at each group transition. Conveniently, the group
transitions are just one element past the length of the previous element, so we
can add the padding at the positions following the cumulative sum of the group lengths:</p>
<pre class="r"><code>id0[cumsum(g.rle[[&#39;lengths&#39;]]) + 1L] &lt;- pad + 1L
head(id0, 22)   # first three groups</code></pre>
<pre><code> [1] 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 8 1 1 1 1 1 1</code></pre>
<p>You’ll notice this is essentially the same thing as <code>diff(id1)</code> <a href="#diff-id1">from
earlier</a>. We reproduce <code>id1</code> by applying <code>cumsum</code>:</p>
<pre class="r"><code>head(cumsum(id0), 22)</code></pre>
<pre><code> [1]  1  2  3  4  5  6  7  8 15 16 17 18 19 20 21 29 30 31 32 33 34 35</code></pre>
<p>A distinguishing feature of these manipulations other than possibly inducing
death-by-boredom is that they are all in fast vectorized code. This gives us
another reasonably fast group sum function. We split it up into a function that
<a href="#embed-fun">calculates the embedding indices</a> and one that does the <a href="#col-sum-fun">embedding
and sum</a>, for reasons that will become obvious later. Assuming
sorted inputs<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>:</p>
<pre class="r"><code>sys.time({
  emb &lt;- og_embed_dat(go)   # compute embedding indices
  og_sum_col(xo, emb)       # use them to compute colSums
})</code></pre>
<pre><code>   user  system elapsed
  0.502   0.195   0.699</code></pre>
<p>Most of the run time is actually the embedding index calculation:</p>
<pre class="r"><code>sys.time(emb &lt;- og_embed_dat(go))</code></pre>
<pre><code>   user  system elapsed
  0.369   0.141   0.510</code></pre>
<p>One drawback is the obvious wasted memory taken up by the padding in the
embedding matrix. This could become problematically large if a small number of
groups are much larger than the rest. It may be possible to mitigate this by
breaking up the data into by group size<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>Overall this is a little slower than <code>rowsum</code> for the simple group sum, but
as we’ll see shortly there are benefits to this approach.</p>
</div>
<div id="pedal-to-the-metal" class="section level1">
<h1>Pedal To The Metal</h1>
<p>For the sake of an absolute benchmark I wrote a <a href="#og_sum_C">C version of <code>rowsum</code>,
<code>og_sum_C</code></a> that takes advantage of group-ordered data to compute the
group sums and counts<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>. Once the data is sorted, this takes
virtually no time:</p>
<pre class="r"><code>sys.time(og_sum_C(xo, go))</code></pre>
<pre><code>   user  system elapsed
  0.039   0.001   0.041</code></pre>
<!--
sys.time({
  o <- order(grp)
  og_sum_C(x[o], grp[o])
})
   user  system elapsed
  0.735   0.004   0.743
-->
<p>The only way to make this substantially faster is to make the sorting faster, or
come up with an algorithm that can do the group sums without sorting and somehow
do it faster than what we have here. Both of these are beyond my reach.</p>
<p>Let’s compare against all the different methods, including the <a href="/2019/06/10/base-vs-data-table/#group-sums">original
<code>cumsum</code> based group sum</a> (<code>cumsum-1</code>), and the <a href="/2019/06/18/hydra-precision/#a-new-hope">precision corrected two
pass version</a> (<code>cumsum-2</code>):</p>
<!-- See static/..._files/scripts/benchmark.Rmd -->
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/sum-benchmarks-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We’re actually able to beat <code>data.table</code> with our custom C code, although that
is only possible because <code>data.table</code> <a href="https://twitter.com/BrodieGaslam/status/1106231241488154626">contributed its fast radix sort to
R</a>, and <code>data.table</code> requires more complex code to be able to run a broader
set of statistics.</p>
<p>The pattern to notice is that for several of the methods the time spent
doing the actual summing is small<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. For example, for <code>colSums</code>
most of the time is ordering and computing the run length encoding / embedding
indices (<code>rle*</code>). This is important because those parts can be re-used if the
grouping is the same across several calculations. It doesn’t help for single
variable group sums, but if we have more variables or more complex statistics it
becomes a factor.</p>
<p>Let’s see how helpful re-using the group-based data is with the calculation of
the slope of a bivariate regression:</p>
<p><span class="math display">\[\frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sum(x_i -
\bar{x})^{2}}\]</span></p>
<p>The calculation requires four group sums, two to compute <code>$\bar{x}$</code> and
<code>$\bar{y}$</code>, and another two shown explicitly with the <code>$\sum$</code> symbol. At the
same time we only need to compute the ordering and the <code>rle</code> / embedding once
because the grouping is the same across all calculations. You can see this
clearly in the <a href="#g_sum_col"><code>colSums</code> based group slope calculation in the
appendix</a>.</p>
<p>When we compare all the previous implementations of the group slope
calculation, against the new <code>rowsum</code> and <code>colSums</code> implementations the
advantage of re-using the group information becomes apparent:</p>
<!-- See static/..._files/scripts/benchmark.Rmd -->
<p><img src="/post/2019-07-26-hydra-loose-ends_files/figure-html/slope-benchmarks-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Even though <code>rowsum</code> was the fastest group sum implementation, it is the
slowest of the base options outside of <code>split/vapply</code> because none of the
computation components other than the re-ordering can be re-used. <code>colSums</code>
does pretty well and has the advantage of not suffering from the precision
issues of <code>cumsum-1</code><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>, and additionally of naturally handling NA and
non-finite values. <code>cumsum-2</code><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> might be the best bet of the “base”
solutions as it is only slightly slower than <code>colSums</code> method, but should scale
better if there are some groups that are much larger than most<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.</p>
<p><code>data.table</code> gets pretty close to the C implementation, but only in the
reformulated form which comes <a href="/2019/07/24/hydra-reformulate/#slow-down-cowboy">with challenging precision issues</a>.</p>
</div>
<div id="thats-all-folks" class="section level1">
<h1>That’s All Folks</h1>
<!-- this needs to become a shortcode -->
<p><a href='#image-credits' title='Click for image credits.' class=image-credit>
<img
  id='front-img'
  src= "/post/2019-05-17-pixie-dust_files/user-imgs/hydra-white.png"
  class='post-inset-image'
/>
</a></p>
<p>Phew, finally done. I never imagined how out of hand some silly benchmarks
against <code>data.table</code> would get. I learned way more than I bargained for, and
come away from the whole thing with a renewed admiration for what R does: it
can often provide near-statically-compiled performance in an interpreted
language right out of the box<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>. It’s not always easy to
achieve this, but in many cases it is possible with a little thought and care.</p>
<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<div id="feedback-cont">

</div>
<p>This post is the last post of the <a href="/tags/hydra/">Hydra Chronicles</a> post series.</p>
</div>
<div id="appendix" class="section level1">
<h1>Appendix</h1>
<div id="acknowledgments" class="section level2">
<h2>Acknowledgments</h2>
<p>These are post-specific acknowledgments. This website owes many additional
thanks to <a href="http://ffmpeg.org/about.html">generous people and organizations</a> that have made it possible.</p>
<ul>
<li><a href="https://twitter.com/thomasp85">Thomas Lin Pedersen</a> and <a href="https://twitter.com/tylermorganwall">Tyler Morgan Wall</a> for <a href="https://github.com/thomasp85/gganimate"><code>gganimate</code></a>
and <a href="https://github.com/tylermorganwall/rayshader"><code>rayshader</code></a><a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> respectively with which I made the
<code>colSums</code> group sum animation frames, and the FFmpeg team for <a href="http://ffmpeg.org/about.html">FFmpeg</a>
with which I stitched the frames into <a href="/post/2019-07-26-hydra-loose-ends_files/scripts/anim.html">the video</a>.</li>
<li><a href="https://github.com/mattdowle">Matt Dowle</a> and the other <a href="https://cloud.r-project.org/web/packages/data.table/"><code>data.table</code> authors</a> for contributing
the radix sort to R without which none of the fast group statistic methods
would be fast.</li>
<li><a href="https://github.com/osklyar">Oleg Sklyar</a>, <a href="https://github.com/eddelbuettel">Dirk Eddelbuettel</a>, <a href="https://github.com/romainfrancois">Romain François</a>, etal. for
<a href="https://github.com/eddelbuettel/inline"><code>inline</code></a> for easy integration of C code into ad-hoc R functions.</li>
<li><a href="https://github.com/hadley">Hadley Wickham</a> and the <a href="https://cran.r-project.org/web/packages/ggplot2/index.html"><code>ggplot2</code> authors</a> for <code>ggplot2</code> with
which I made many the plots in this post.</li>
<li>Simon Urbanek for the <a href="https://cran.r-project.org/web/packages/png/index.html">PNG
package</a> which I used
in the process of manipulating the animation frames.</li>
<li><a href="https://github.com/sjmgarnier">Simon Garnier</a> etal. for <a href="https://cran.r-project.org/web/packages/viridisLite/"><code>viridisLite</code></a>, and by extension the
<a href="https://github.com/matplotlib/matplotlib/"><code>matplotlib</code></a> team from which it was ported.</li>
<li><a href="http://www.personal.psu.edu/cab38/">Cynthia Brewer</a> for color brewer palettes, <a href="http://colorbrewer2.org/#type=qualitative&amp;scheme=Set2&amp;n=3">one of which</a> I used in
some plots, and <a href="https://www.axismaps.com/">axismaps</a> for the web tool for picking them.</li>
</ul>
</div>
<div id="image-credits" class="section level2">
<h2>Image Credits</h2>
<ul>
<li><a href="https://www.flickr.com/photos/wentzelepsy/15431618539/in/photolist-pvD5yB-orMGkS-oD9tMr-6Hy4vZ-dHArXF-4MkiSq-fmXesZ-fnKybA-7PdCYt-nKGMUu-9DwyBF-4RGwKf-95vYq-4YHwip-69ckvt-FwgCQm-95vLz-6w9W6f-bVZLqM-95vWc-4YHsJc-4YJhhV-fnvhfn-9DzB8h-4YHxAB-9db7nP-fnvrrP-Ww91p9-8Yhwn3-4tLnpy-bsHuHt-4RGJSU-8nLdkA-4MkjF5-4tLnzC-5Zr3e9-fnKFf7-69gAij-5sR6jQ-9DwEzx-gfesaD-fnf39A-6w5JmX-69gz5o-5xYUVS-6MLZD9-5N2EcN-X463Df-G23wk-fmXqjH">Hydra With Fedora(s)</a>, by <a href="https://www.flickr.com/photos/wentzelepsy/">Larry Wentzel</a>, under CC BY-NC 2.0,
haberdashery and haberdasher removed.</li>
</ul>
</div>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.0 (2019-04-26)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Mojave 10.14.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] data.table_1.12.2 gganimate_1.0.3   ggplot2_3.2.0     rayshader_0.11.5 

loaded via a namespace (and not attached):
 [1] rgl_0.100.19            Rcpp_1.0.1              prettyunits_1.0.2      
 [4] png_0.1-7               ps_1.3.0                assertthat_0.2.1       
 [7] rprojroot_1.3-2         digest_0.6.19           foreach_1.4.4          
[10] mime_0.7                R6_2.4.0                imager_0.41.2          
[13] tiff_0.1-5              plyr_1.8.4              backports_1.1.4        
[16] evaluate_0.14           blogdown_0.12           pillar_1.4.1           
[19] rlang_0.4.0             progress_1.2.2          lazyeval_0.2.2         
[22] miniUI_0.1.1.1          rstudioapi_0.10         callr_3.2.0            
[25] bmp_0.3                 rmarkdown_1.12          desc_1.2.0             
[28] devtools_2.0.2          webshot_0.5.1           servr_0.13             
[31] stringr_1.4.0           htmlwidgets_1.3         igraph_1.2.4.1         
[34] munsell_0.5.0           shiny_1.3.2             compiler_3.6.0         
[37] httpuv_1.5.1            xfun_0.8                pkgconfig_2.0.2        
[40] pkgbuild_1.0.3          htmltools_0.3.6         readbitmap_0.1.5       
[43] tidyselect_0.2.5        tibble_2.1.3            bookdown_0.10          
[46] codetools_0.2-16        crayon_1.3.4            dplyr_0.8.3            
[49] withr_2.1.2             later_0.8.0             grid_3.6.0             
[52] xtable_1.8-4            jsonlite_1.6            gtable_0.3.0           
[55] magrittr_1.5            scales_1.0.0            cli_1.1.0              
[58] stringi_1.4.3           farver_1.1.0            fs_1.3.1               
[61] promises_1.0.1          remotes_2.0.4           doParallel_1.0.14      
[64] testthat_2.1.1          iterators_1.0.10        tools_3.6.0            
[67] manipulateWidget_0.10.0 glue_1.3.1              tweenr_1.0.1           
[70] purrr_0.3.2             hms_0.4.2               crosstalk_1.0.0        
[73] jpeg_0.1-8              processx_3.3.1          pkgload_1.0.2          
[76] parallel_3.6.0          colorspace_1.4-1        sessioninfo_1.1.1      
[79] memoise_1.1.0           knitr_1.23              usethis_1.5.0          </code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<pre class="r"><code>RNGversion(&quot;3.5.2&quot;); set.seed(42)
n     &lt;- 1e7
n.grp &lt;- 1e6
grp   &lt;- sample(n.grp, n, replace=TRUE)
noise &lt;- rep(c(.001, -.001), n/2)  # more on this later
x     &lt;- runif(n) + noise
y     &lt;- runif(n) + noise          # we&#39;ll use this later</code></pre>
</div>
<div id="functions" class="section level2">
<h2>Functions</h2>
<div id="sys.time" class="section level3">
<h3>sys.time</h3>
<pre class="r"><code># Run `system.time` `reps` times and return the timing closest to the median
# timing that is faster than the median.

sys.time &lt;- function(exp, reps=11) {
  res &lt;- matrix(0, reps, 5)
  time.call &lt;- quote(system.time({NULL}))
  time.call[[2]][[2]] &lt;- substitute(exp)
  gc()
  for(i in seq_len(reps)) {
    res[i,] &lt;- eval(time.call, parent.frame())
  }
  structure(res, class=&#39;proc_time2&#39;)
}
print.proc_time2 &lt;- function(x, ...) {
  print(
    structure(
      x[order(x[,3]),][floor(nrow(x)/2),],
      names=c(&quot;user.self&quot;, &quot;sys.self&quot;, &quot;elapsed&quot;, &quot;user.child&quot;, &quot;sys.child&quot;),
      class=&#39;proc_time&#39;
) ) }</code></pre>
</div>
<div id="og_sum_col" class="section level3">
<h3>og_sum_col</h3>
<p>The <code>og_</code> prefix stands for “Ordered Group”.</p>
<p>Compute indices to embed group ordered data into a regular matrix:<span id="embed-fun"></span></p>
<pre class="r"><code>og_embed_dat &lt;- function(go) {
  ## compute run length encoding
  g.rle &lt;- rle(go)
  g.lens &lt;- g.rle[[&#39;lengths&#39;]]
  max.g &lt;- max(g.lens)

  ## compute padding
  g.lens &lt;- g.lens[-length(g.lens)]
  g.pad &lt;- max.g - g.lens + 1L

  ## compute embedding indices
  id0 &lt;- rep(1L, length(go))
  id0[(cumsum(g.lens) + 1L)] &lt;- g.pad
  id1 &lt;- cumsum(id0)

  list(idx=id1, rle=g.rle)
}</code></pre>
<p>And use <code>colSums</code> to compute the group sums:<span id="col-sum-fun"></span></p>
<pre class="r"><code>og_sum_col &lt;- function(xo, embed_dat, na.rm=FALSE) {
  ## group sizes
  rle.len &lt;- embed_dat[[&#39;rle&#39;]][[&#39;lengths&#39;]]

  ## allocate embedding matrix
  res &lt;- matrix(0, ncol=length(rle.len), nrow=max(rle.len))

  ## copy data using embedding indices
  res[embed_dat[[&#39;idx&#39;]]] &lt;- xo
  setNames(colSums(res, na.rm=na.rm), embed_dat[[&#39;rle&#39;]][[&#39;values&#39;]])
}</code></pre>
</div>
<div id="og_sum_c" class="section level3">
<h3>og_sum_C</h3>
<p>Similar to <code>rowsum</code>, except it requires ordered input, and it returns group
sizes as an attribute. Group sizes allow us to either compute means or recycle
the result statistic back to the input length.</p>
<p>This is a limited, lightly tested, implementation that only works for double <code>x</code>
values and relies completely on the native code to handle NA/Infinite values.
It will ignore dimensions of matrices, and has undefined behavior if any group
has more elements than than <code>INT_MAX</code>.</p>
<p>Inputs must be ordered in increasing order by group, with if it exists the NA
group last. The NA group will be treated as a single group (i.e. NA==NA is
TRUE).</p>
<pre class="r"><code>og_sum_C &lt;- function(x, group) {
  stopifnot(
    typeof(x) == &#39;double&#39;, is.integer(group), length(x) == length(group)
  )
  tmp &lt;- .og_sum_C(x, group)
  res &lt;- setNames(tmp[[1]], tmp[[2]])
  attr(res, &#39;grp.size&#39;) &lt;- tmp[[3]]
  res
}
.og_sum_C &lt;- inline::cfunction(
  sig=c(x=&#39;numeric&#39;, g=&#39;integer&#39;),
  body=&quot;
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_n;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\&quot;Unequal Length Vectors\&quot;);
  res = PROTECT(allocVector(VECSXP, 3));

  if(len &gt; 1) {
    // count uniques
    for(i = 1; i &lt; len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));
    res_n = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    int *res_gi = INTEGER(res_g);
    int *res_ni = INTEGER(res_n);
    R_xlen_t j = 0;
    R_xlen_t prev_n = 0;

    res_xi[0] = 0;
    for(i = 1; i &lt; len; ++i) {
      res_xi[j] += xi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] &lt; gi[i]){
        res_gi[j] = gi[i - 1];
        res_ni[j] = i - prev_n;  // this could overflow int; undefined?
        prev_n = i;
        ++j;
        res_xi[j] = 0;
      } else error(\&quot;Decreasing group order found at index %d\&quot;, i + 1);
    }
    res_xi[j] += xi[i - 1];
    res_gi[j] = gi[i - 1];
    res_ni[j] = i - prev_n;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    SET_VECTOR_ELT(res, 2, res_n);
    UNPROTECT(3);
  } else {
    // Don&#39;t seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
&quot;)</code></pre>
</div>
<div id="g_slope_col" class="section level3">
<h3>g_slope_col</h3>
<p>Compute the slope using the <a href="#og_sum_col"><code>colSums</code> based group sum</a>. Notice
how we compute the embedding indices once, and re-use them for all four group
sums.</p>
<pre class="r"><code>g_slope_col &lt;- function(x, y, group) {
  ## order
  o &lt;- order(group)
  go &lt;- group[o]
  xo &lt;- x[o]
  yo &lt;- y[o]

  ## compute group means for x/y
  emb &lt;- og_embed_dat(go)                    # &lt;&lt; Embedding
  lens &lt;- emb[[&#39;rle&#39;]][[&#39;lengths&#39;]]
  ux &lt;- og_sum_col(xo, emb)/lens             # &lt;&lt; Group Sum #1
  uy &lt;- og_sum_col(yo, emb)/lens             # &lt;&lt; Group Sum #2

  ## recycle means to input vector length and
  ##  compute (x - mean(x)) and (y - mean(y))
  gi &lt;- rep(seq_along(ux), lens)
  x_ux &lt;- xo - ux[gi]
  y_uy &lt;- yo - uy[gi]

  ## Slope calculation
  gs.cs &lt;-
    og_sum_col(x_ux * y_uy, emb) /           # &lt;&lt; Group Sum #3
    og_sum_col(x_ux ^ 2, emb)                # &lt;&lt; Group Sum #4
  setNames(gs.cs, emb[[&#39;rle&#39;]][[&#39;vaues&#39;]])
}
sys.time(g_slope_col(x, y, grp))</code></pre>
<pre><code>   user  system elapsed
  2.268   0.497   2.765</code></pre>
</div>
<div id="g_slope_c" class="section level3">
<h3>g_slope_C</h3>
<p>This is a very lightly tested all C implementation of the group slope.</p>
<pre class="r"><code>g_slope_C &lt;- function(x, y, group) {
  stopifnot(
    typeof(x) == &#39;double&#39;, is.integer(group), length(x) == length(group),
    typeof(y) == &#39;double&#39;, length(x) == length(y)
  )
  o &lt;- order(group)
  tmp &lt;- .g_slope_C(x[o], y[o], group[o])
  res &lt;- setNames(tmp[[1]], tmp[[2]])
  res
}
.g_slope_C &lt;- inline::cfunction(
  sig=c(x=&#39;numeric&#39;, y=&#39;numeric&#39;,  g=&#39;integer&#39;),
  body=&quot;
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_y;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  double *yi = REAL(y);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\&quot;Unequal Length Vectors\&quot;);
  res = PROTECT(allocVector(VECSXP, 2));

  if(len &gt; 1) {
    // First pass compute unique groups
    for(i = 1; i &lt; len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_y = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    double *res_yi = REAL(res_y);
    int *res_gi = INTEGER(res_g);
    R_xlen_t j = 0;
    R_xlen_t prev_i = 0, n;

    // Second pass compute means

    double xac, yac;
    yac = xac = 0;
    for(i = 1; i &lt; len; ++i) {
      xac += xi[i - 1];
      yac += yi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] &lt; gi[i]){
        n = i - prev_i;
        res_xi[j] = xac / n;
        res_yi[j] = yac / n;
        res_gi[j] = gi[i - 1];
        prev_i = i;
        yac = xac = 0;
        ++j;
      } else error(\&quot;Decreasing group order found at index %d\&quot;, i + 1);
    }
    xac += xi[i - 1];
    yac += yi[i - 1];
    n = i - prev_i;
    res_xi[j] = xac / n;
    res_yi[j] = yac / n;
    res_gi[j] = gi[i - 1];

    // third pass compute slopes

    double xtmp, ytmp;
    yac = xac = xtmp = ytmp = 0;
    j = 0;

    for(i = 1; i &lt; len; i++) {
      xtmp = xi[i - 1] -  res_xi[j];
      ytmp = yi[i - 1] -  res_yi[j];
      xac += xtmp * xtmp;
      yac += ytmp * xtmp;

      if(gi[i - 1] == gi[i]) {
        continue;
      } else {
        res_xi[j] = yac / xac;
        yac = xac = 0;
        ++j;
      }
    }
    xtmp = xi[i - 1] -  res_xi[j];
    ytmp = yi[i - 1] -  res_yi[j];
    xac += xtmp * xtmp;
    yac += ytmp * xtmp;
    res_xi[j] = yac / xac;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    UNPROTECT(3);
  } else {
    // Don&#39;t seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
&quot;)</code></pre>
<!-- Original Hydra Link
Larry Wentzel
https://www.flickr.com/photos/wentzelepsy/
Attribution-NonCommercial 2.0 Generic (CC BY-NC 2.0)
-->
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><code>tapply</code> calls <code>lapply</code> internally, not <code>sapply</code>, but the
semantics of the default <code>simplify=TRUE</code> case are equivalent. Additionally,
the simplification isn’t done with <code>c</code> as suggested by the diagram, but in
this case with scalar return values from <code>sum</code> it’s also semantically
equivalent.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>I use single threaded timings as those are more stable, and
it allows apples-to-apples comparisons. While it is a definite advantage that
<code>data.table</code> comes with its own built-in parallelization, enabling its use
means the benchmarks are only relevant for R processes that are themselves not
parallelized.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><code>rowsum</code> returns a matrix even in the one column case so we
drop the dimensions with <code>c</code> to make the comparison to <code>colSums</code> more obvious.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>We could have the function sort the inputs itself, but doing
it this way allows us to compare to the other functions for which we pre-sort,
and to re-use the ordering data when summarizing multiple variables.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>I implemented a test version to test feasibility and it had
comparable performance<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>With group-ordered data we can detect group transitions any time
the value of the group vector changes. We can use that as a trigger to
transfer the accumulator value to the result vector and reset it.
We did something similar with our <a href="/2019/06/10/base-vs-data-table/#interlude-better-living-through-sorted-data">re-implementation of <code>unique</code> for sorted
data</a>.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p><code>sum</code> time is essentially all time that is neither ordering,
<code>rle</code>, or embedding index calculation, so for some functions it includes steps
other than just summing.<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Original <a href="/2019/06/10/base-vs-data-table/#group-sums">single pass <code>cumsum</code></a> based group sum.<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p><code>cumsum</code> based group sum with <a href="/2019/06/18/hydra-precision/#a-new-hope">second precision correcting
pass</a>. In this case we use the second pass for every one of the four
group sums.<a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Note we’ll really need to use the more complex and probably slightly
slower <a href="/2019/06/10/base-vs-data-table/#cumulative-group-sum-with-na-and-inf">version that handles NAs and non-finite values</a>.<a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>I consider ~3x close given that typically differences
between statically compiled and interpreted coder are more on the order of
~10-100x.<a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>I used <code>rayshader</code> primarily to compute the shadows on the
texture of the 3D plots. Obviously the idea of the 3D <code>ggplot</code> comes from
<code>rayshader</code> too, but since I do not know how to control it precisely enough to
merge the frames from its 3D plots into those of <code>gganimate</code> I ended up using
my own half-baked 3D implementation. I’ve <a href="/post/2019-07-26-hydra-loose-ends_files/scripts/threed-plot.R">recorded the code</a> for the
curious, but be prepared to recoil in horror. For an explanation of how the
3D rendering works see the <a href="/2018/12/12/three-d-pipeline/">Stereoscopic post</a>.<a href="#fnref12" class="footnote-back">↩</a></p></li>
</ol>
</div>
