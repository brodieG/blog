---
title: Elegant R Semantics
author: ~
date: '2019-01-01'
slug: elegant-r-semantics
draft: true
categories: [r]
tags: []
---

# R Semantics are Wonderful

R catches a lot of flak because its idiosyncrasies can be confusing to the
uninitiated.  Some are genuine historic infelicities that would probably be
fixed were they not relied on by existing code.  Most of them are a
manifestation of the powerful philosophy underlying the language:

* Vector based data structures.
* Everything is data.
* Freedom.

On the surface R looks like a traditional C style language, but the first two
principles above make it something entirely different.  Freedom means there is a
bewildering number of ways you can accomplish any given task, many of which are
computationally inefficient.  All of this can make for a trying experience for
first-time users wanting to do some quick analysis.

A way to cope with this is to embrace frameworks such as the [Tidyverse][1] that
mask much of the apparent complexity of the language.  This allows beginners to
produce "useful" analysis faster[^2].  For many this will be the right
trade-off, but it is a trade-off.  The primary issue is that the Tidyverse runs
in R, so it is inevitable that sooner or later Tidyverse users will have to deal
with R semantics.  This means learning two sets of possibly conflicting
semantics.

Another approach is to invest time and effort to understand the foundational
concepts behind R semantics.  This too is a trade-off as a basic understanding
of R semantics alone is insufficient to do "useful" analysis.  You will need to
build off of those.  But the reward is to recognize the seeming bewildering
idiosyncrasies of R as the elegant interactions of the foundational concepts of
the language.  The beauty of it is that the foundational concepts are simple.

WHEN ONE APPROACH MAKES MORE SENSE THAN THE OTHER?

This blog post looks to highlight some of the interesting ways one can extend
the basic R principles into useful higher level calculations.  For a detailed
review of the principles please read the criminally under-rated [R Language
Definition][2].

# Vector Based Data Structures

The basic data structure in R is the vector:

```{r}
vec <- 1:12
vec
```

`vec` is stored in memory as twelve 32-bit[^3] contiguous sections of memory.

One of the foundational principles of R is that vectors can be interpreted as
complex data structures by attaching meta-data to them without changing the
underlying vector.  This is a simple and elegant alternative to defining custom
C-level data structures.

We can turn our vector into an matrix by adding a 'dim' attribute[^4]:

```{r}
mx <- vec
attr(mx, 'dim') <- c(3, 4)
mx
```

Even though the underlying data is unchanged, its semantics change. R
comes with several built-in special attributes like 'dim' that induce
data-structure specific semantics.  Additionally the 'class' attribute can be
used in combination with generic functions to attach any interpretation
imaginable[^5] to data.

The mere addition of the 'dim' attribute allows magic like matrix multiplication
on what are really one dimensional vectors.  At the same time, R can re-use all
its internal C vector code for matrices for cases where the semantics are the
same as in simple arithmetic operations:

```{r}
vec + 1
c(mx + 1)   # `c` drops the dim attribute
```

And anyone aware of the underlying vector structure of matrices (and recycling
semantics) realizes that you can add vectors column-wise to matrices:

```{r}
mx + (1:3) * 100
```

Or row-wise with transposition or repetition:

```{r}
t(t(mx) + (1:4) * 100)
mx + rep(1:4, each=nrow(mx))
```

The "dual" nature of matrices and arrays[^6] provides many opportunities for
creative manipulation.

We have been looking primary at numeric vectors, but there are several others.
There are logical vectors, and character vectors, and also list vectors:

```{r}
list(1, list(1,2), 'hello')
```

But how can lists be vectors if vectors are supposed to be a sequence of
contiguous, equal-size, equal-type elements?  It is because the list proper is a
vector of pointers that link to the actual contents.  The pointers themselves
are equal size and equal type, even though the "contents" are not.  If this
seems odd, realize that character vectors are the same.  They are vectors of
pointers to strings which themselves are often different sizes.

Since lists are vectors, we can also add dim attributes to them and get
meaningful results:

```{r}
set.seed(42)
l <- replicate(12, runif(10), simplify=FALSE)
dim(l) <- c(3, 4)
l
l[[3, 2]]
```

While list-matrices are a bit odd they do have uses we'll discuss shortly.  The
important point for now is that we started with the simple concept of vectors
and attributes, and ended up with strange but useful list-matrices.  R allowed
us to combine simple concepts to create useful complexity.

DATAFRAMES?  `lapply` over columns?

# Everything is Data

Certainly this is true of anything that happens on a computer, but R embraces
this wholeheartedly in a way that many programming languages don't.  I still
recall my consternation when I first started using R and typed the following
into the terminal thinking I had a variable defined by that name:

```{r}
var    # my actual variable was var1
```

R happily went ahead and displayed the contents of the `var` function as it
would display the contents of any "normal" variable.  That functions were stored
in variables as any other data felt more like a curiosity or even an annoyance
than anything else:

```{r}
var(1:10)
variance <- var
var <- 1:10
variance(var)
```

This was before I fully appreciated that while R can behave like a traditional
imperative language, it has a strong functional bent.  The simple example is the
venerable `lapply`:

```{r}
lapply(list(sample(5), 3:1), FUN=sort)
```

While this is no faster than a `for` loop, it does create the return structure
for you which is convenient.  More generally, R defines several functions that
will loop over data structures in a particular way with a deterministic return
structure[^6], and allows you to substitute the processing logic by providing
a function as an input.

Of course we can always loop over simple lists with `lapply`, but more
interesting possibilities are available when we understand the underlying vector
structure of the object that we're dealing with.

Another source of consternation for me when I first picked up R was data frames.
I really expected the two expressions to be equivalent:

```{r}
length(USArrests)
nrow(USArrests)
```

Obviously these are different because data frames are really lists of vectors
with a class attribute that allows them to be interpreted as two dimensional
tables:

```{r}
str(unclass(USArrests))
```

There is no special internal data frame structure.  We're just re-using the
existing vector structures.  Since the date frame "container" is a list of the
columns, it is completely natural that `length` should return the number of
columns.  More generally we can exploit that dual nature as we did with
matrices.  For example, to compute column-wise statistics we can just run:

```{r}
lapply(iris[1:4], sd)
```



But now that I realize that the R way is all about vectors and attributes, and
that data frames are lists of equal length vectors passing themselves off as
tables, I know that 



It is also possible to manipulate functions to modify their behavior just as you
might manipulate data to change its value:

```{r}
Negate(is.na)(NA)
```


```{r}
Reduce(setdiff, list(1:3, 2:5, 4:8))
```

* Reduce
* do.call
* outer


That was before I became


* Functions
* Language
* do.call
* Functional

# Freedom

* rpn calculator


I believe the latter approach is better if you intend to use R on a regular
basis.

And once
you fully grasp the key building blocks the freedom is exhilarating[^1].

It would take more than a blog post to teach the foundational blocks of R
semantics.  Instead, I will go through a few examples that illustrate how you
can build useful complexity out of simple in an effort to demonstrate that you
can do some pretty neat stuff once you truly understand the basics.

I'll illustrate in this post some of the semantics that I find particularly
satisfying.

# Vectors

# Concessions to Common Semantic Standards

Disguising things to look like other things: language like language, operators
like operators.


# Functions are Data

# Everything is a List Or Can Be Made Into One

# Computing on the Language

RPN calculator.

```{r}
chr_to_name <- function(y)
  lapply(y, function(x) if(is.numeric(x)) x else as.name(x))

rpn <- function(...) {
  l <- chr_to_name(list(...))
  i <- 1
  while(length(l) >= i) {
    if(is.name(l[[i]])) {
      l[[i - 2]] <- as.call(l[i - c(0, 2, 1)])
      l[i:(i - 1)] <- NULL
      i <- i - 1
    } else {
      i <- i + 1
    }
  }
  l[[1]]
}


rpn <- function(...) {
  rpn_rec <- function(tl, hd=list())
    if(length(tl)) {
      hd <- if(is.numeric(tl[[1]])) c(hd, tl[1])
      else c(head(hd, -2), list(as.call(c(tl[1], tail(hd, 2)))))
      Recall(tl[-1], hd)
    } else hd[[1]]
  rpn_rec(chr_to_name(list(...)))
}


  rpn2 <- function(...) rpn_rec(list(), chr_to_name(list(...)))


rpn(3, 4, '+', 5, '*', pi, 2, '-', '/')
l <- list(3, 4, as.name('+'), 5, as.name('*'), pi, 2, as.name('-'), as.name('/'))

rpn(3, 4, '+', 5, '*')

rpn <- function(...) {
  l <- lapply(list(...), function(x) if(is.numeric(x)) x else as.name(x))
  for(i in seq(2, length(l), 1))
    if(!is.numeric(l[[i]])) l[[i]] <- as.call(l[i - 0:2])
  l[[length(l)]]
}
```

# Things that are Different Have The Same Semantics

# Limits

* Vectorization

# References

* R language definition
* Inferno

that's neither here
nor there.

What matters is that a few key decisions

Some of them are historical infelicities that
will forever remain etched in the foundations


One of the amazing things about R is how it is built on well thought-out basic
principles that extend elegantly.

# Vectors


# Matrices


# Lists

# List-Matrices

# Everything is a List

[^1]: Degree of exhilaration may vary.  Perhaps I don't get out much.
[^2]: My initial experience with R predates the tidyverse, so I don't have
  personal experience with this.  Nor have I done A/B testing with beginners
  that use the tidyverse vs. not, but I have no reason to doubt the assertion.
[^3]: As of this writing this is the case.
[^4]: A safer way to create matrices is with the `matrix` constructor, although
  ultimately what makes an R matrix a matrix is the presence of the 'dim'
  attribute.
[^5]: We won't cover the details here, but see the [objects chapter of the R
  Language Definition][2] for details.
[^6]: Arrays are matrices generalized to three or more dimensions.
[^7]: The `*apply` family of functions, `outer`.

[1]: https://cran.r-project.org/doc/manuals/R-lang.html#Vector-objects
[2]: (https://cran.r-project.org/doc/manuals/R-lang.html#Object_002doriented-programming)
