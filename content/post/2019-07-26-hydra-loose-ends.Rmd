---
title: "Hydra Chronicles Part V: Loose Ends"
author: ~
date: '2019-07-26'
slug: hydra-loose-ends
categories: [r]
tags: [group-stats,optim,hydra]
image: /front-img/default.png
imagerect: ~
imagemrgvt: 0%
imagemrghz: 0%
weight: 1
contenttype: article
description: Front page summary
---

```{r echo=FALSE}
options(digits=3)
knitr::opts_chunk$set(comment = "", fig.align='center', error=TRUE)
```

# Almost Done!

<!-- this needs to become a shortcode -->
<img
  id='front-img' src='/front-img/default.png'
  class='post-inset-image'
/>

Fingers crossed this will be the last post of the [Hydra Chronicles][100], a.k.a.
"Everything You Didn't Want To Know About Group Statistics But Let Me Tell You
Anyway".  Well, it's more of an end note rather than a real post: a few tidbits
that ended up on the cutting floor in the earlier posts.

One of our early "discoveries" about group statistics is that if we can compute
the group sum, we can build on that to compute many other group statistics.
We'll go over here a few of the other strategies I tested out before I settled
on the [`cumsum` based approach][110] we used to "beat" `data.table`.

# rowsum

I did mention this one [in passing][120], but it bears re-examining:
`base::rowsum` is a remarkable creature in the base R ecosystem.  As far as I
know, it is the only R function that can compute group statistics on unequal
group sizes in native code.  Despite that, it feels like a relatively
unknown function.  In my own experience, I've seen infinitely more uses of
`base::rowSums` than `base::rowsum`.  As you might imagine my attempts to get
firmer evidence from search engines was fruitless.  Perhaps `rowsum` hides
from others behind the shadow of the capitalization and pluralization of
`rowSums`, as it did for many years for me.  Or maybe I'm just the idiot that
missed The Memo.

In the spirit of a code snippet is worth a thousand words, and using our beaten
to death 10MM row, ~1MM group [data set](#data):

```{r eval=FALSE}
sys.time(gsum.0 <- tapply(x, grp, sum))
```
```
   user  system elapsed
  6.956   0.112   7.107
```
```{r eval=FALSE}
sys.time(gsum.1 <- rowsum(x, grp))
```
```
   user  system elapsed
  2.359   0.048   2.430
```

`sys.time` is a [wrapper around `system.time` defined in the
appendix](#sys-time).

```{r eval=FALSE}
all.equal(c(gsum.0), c(gsum.1), check.attributes=FALSE)
```

`rowsum` provides similar functionality to `tapply(..., sum)` (or equivalently,
`vapply(split(...), sum, 0)` with a single grouping variable, but with a
noticeable speed-up as it can avoid the per-group R-level calls.  Speed is
improved even when pre-ordering the inputs, although the difference between the
methods is similar as the ordering becomes a substantial portion of the overall
run time.

Even so `rowsum` is sub-optimal because internally it uses a hash table, which
is [inefficient with ordered data][130].  It also does not return the group
sizes which could easily be computed along the sums and we are likely to want
when computing more complex statistics.

# colSums

`base::rowSums` and `base::colSums` are better known than `base::rowsum`, and
they also compute group statistics in native code.  Well, kind of, they do if
you consider rows and columns respectively to be groups.  This is far more
restrictive than `rowsum` where we explicitly specify an arbitrary  grouping
vector, but we can work around it.  The idea is to use clever indexing to embed
the values associated with each group into their own columns.

Suppose we have a vector with 95 elements in ten groups, the vector wrapped
column-wise every ten elements for display purposes, and the groups designated
by a color.  The values of the vector are not shown explicitly.  Then, to
compute group sums we would:

<!--
See static/post/2019-07-26-hydra-loose-ends_files/scripts/ for the code used to
generate the flipbook and animation.
-->

<script type='text/javascript'>
var img_dir = '/post/2019-07-26-hydra-loose-ends_files/user-imgs/flip-book/';
var fps_def = 0.5;
var img_n = 6;
var playing = true;
</script>
```{r child='../../static/chunks/flipbook.Rmd'}
```

The embedding step warrants additional explanation.  The trick is to generate a
vector that maps the positions in our irregular input vector into the regular
matrix.  There are several ways we could do this, but the one that we'll use
today takes advantage of the underlying storage of matrices as vectors.
Let's look at our data before and after embedding, showing the indices in vector
format for both our ordered vector and the target matrix:

```{r echo=FALSE}
 # Horrible horrible, but it works

set.seed(1)
gn <- 10
g <- sample(seq_len(gn), 95, replace=TRUE)
levels <- c('start', 'order', 'longest', 'allocate', 'embed', 'colSums')

 # labels are:
 # 0: original colored squares
 # 1: first set of re-allocation (first column)
 # 3: rest of reallocation
 # 4: background for colored squares
 # 5: original colored squares, but after the move

dat0 <- data.frame(
  step=1L, id=seq_along(g), g,
  x=(seq_along(g) - 1) %/% 10, y=-((seq_along(g) - 1) %% 10),
  alpha=1, label=0
)
dat10 <- rbind(transform(dat0, label=4, g=NA), dat0)
dat20 <- transform(dat10, step=2L)
dat20 <- rbind(
  subset(dat20, label==4),
  transform(
    subset(dat20, label==0)[order(g),],
    x=(seq_along(g) - 1) %/% 10, y=-((seq_along(g) - 1) %% 10)
  )
)
g.rle <- with(subset(dat20, label==0), rle(g))

dat30 <- transform(
  dat20, step=3L,
  alpha=ifelse(
    g==g.rle[['values']][which.max(g.rle[['lengths']])], 1, .2
  )
)
g.max <- nrow(subset(dat30, alpha==1))
dat30 <- rbind(
  dat30,
  transform(subset(dat30, alpha==1), g=NA, label=1)
)
dat30 <- rbind(
  subset(dat30, label%in%c(0,4)),
  transform(
    subset(dat30, label==1), x=gn + 1, y=-(seq_along(y) - 1)
  )
)
dat30 <- do.call(
  rbind,
  c(
    list(dat30),
    replicate(
      gn - 1L, transform(subset(dat30, label==1), label=3), simplify=FALSE)
) )
dat30[dat30[['label']] == 3, 'id'] <- seq_along(which(dat30[['label']] == 3))
dat50 <- transform(
  dat30,
  step=4L,
  alpha=1
)
dat50[dat50[['label']] %in% c(1,3),] <- transform(
  subset(dat50, label %in% c(1,3)),
  x=rep((seq_len(gn)) + gn, each=g.max)
)
dat60 <- transform(
  rbind(
    subset(dat50, label %in% c(1,3,4)),
    transform(
      subset(dat50, label==0), x=gn + g, y=-sequence(g.rle[['lengths']]) + 1
    )
  ),
  step=5L
)
dat70 <- transform(
  rbind(
    subset(dat60, label %in% c(1, 3, 4)),
    transform(subset(dat60, label == 0), y=0)
  ),
  step=6L
)
steps <- c(
  "Start",
  "Order by Group",
  "Compute Length of Longest Group",
  "Alloc Matrix w/ Enough Rows to Fit Longest Group in One Col",
  "Copy Each Group Into a Col",
  "Compute colSums"
)
dat <- transform(
  rbind(dat10, dat20, dat30, dat50, dat60, dat70),
  step=factor(steps[step], levels=steps)
)
 # Code to line up with the steps

code <- c(
'set.seed(1)
g <- sample(10, 95, r=TRUE) # groups
x <- runif(95)              # values',

'o <- order(g)
go <- g[o]
xo <- x[o]',

"g.rle <- rle(go)
g.lens <- g.rle[['lengths']]
g.max <- max(g.lens)",

"res <- matrix(
  0, ncol=length(g.lens), nrow=g.max
)",

"pad <- g.max - g.lens + 1L
id.raw <- rep(1L, length(xo))
id.raw[(cumsum(g.lens) + 1L)] <- pad
id <- cumsum(head(id.raw, -1L))
res[id] <- xo",

"colSums(res)"
)
dat.code <- data.frame(text=code, step=factor(steps))
dat <- dat[with(dat, order(step, -label)),]

 # dat <- subset(dat, step==steps[[5]])
 # dat.code <- subset(dat.code, step==steps[[5]])

library(ggplot2)
library(gganimate)

make_plot <- function(dat, dat.code) {
  ggplot(dat) +
    geom_tile(
      aes(x, y, fill=g, alpha=I(alpha), group=paste(label, id)),
      color='#AAAAAA'
    ) +
    scale_fill_viridis_c(guide=FALSE, na.value='#F3F3F3') +
    scale_alpha(guide=FALSE, rescaler=function(x, to, from, ...) x) +
    theme(
      panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
      axis.title.x=element_blank(), axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.title.y=element_blank(), axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),
      plot.title=element_text(size=16)
    ) + if(!is.null(dat.code)) {
      geom_text(
        data=dat.code, aes(label=text), x=-0.5, y=-10,
        hjust=0, vjust=1, size=6, family='mono'
      )
    }
}
p <- make_plot(dat, dat.code)

# ## gganimate
# 
# p + facet_wrap(~step)
# anim_save(
#   '~/Downloads/colsums-anim.gif',
#   p +  transition_states(step, wrap=FALSE, state_length=4) +
#     labs(title = "{closest_state}"),
#   width=800, height=557, end_pause=5, nframes=350, fps=25
# )
# 
# ## pngs for flipbook
# 
# png.root <- '~/Downloads/colsums/img-%03d.png'
# 
# for(i in 1:6) {
#   png(sprintf(png.root, i), width=800, height=557)
#   dat.sub <- subset(dat, step==steps[[i]])
#   dat.code.sub <- subset(dat.code, step==steps[[i]])
# 
#   p <- make_plot(dat.sub, dat.code.sub) +
#     ggtitle(steps[[i]]) +
#     coord_cartesian(xlim=c(0,20), ylim=c(0,-13))
#   print(p)
#   dev.off()
# }

## Additional frames

dat.sub <- rbind(
  subset(dat, step==steps[[5]] & label!=0),
  transform(subset(dat, step==steps[[5]] & label==0), alpha=0.3),
  transform(
    subset(dat, step==steps[[4]] & label==0), step=steps[[5]], label=5
  )
)
dat.code.sub <- subset(dat.code, step==steps[[5]])

p <- make_plot(dat.sub, NULL)

idx1 <- subset(dat.sub, label==5, select=c(x, y, g))
idx2 <- subset(dat.sub, label%in%c(0,1,3), select=c(x, y, g))
idx2 <- idx2[with(idx2, order(x, -y, g)),]
idx2.dup <- duplicated(idx2[1:2])
idx2 <- idx2[!idx2.dup,]

idx <- rbind(
  transform(idx1[with(idx1, order(x, -y)),], label=seq_along(x)),
  transform(idx2[with(idx2, order(x, -y)),], label=seq_along(x))
)
p + geom_text(data=idx, aes(x, y, label=label, colour=factor(g))) +
  scale_colour_manual(
    guide=FALSE, values=rep(c('white', 'black'), c(2, 8)), na.value='black'
  )
```

The indices corresponding to each group stop matching after the first group due
to the unused elements of the embedding matrix.  What we're looking for is a
fast way to generate the indices in the colored cells in the matrix on the
right.  Let's illustrate in more detail by looking at the first three groups:

One big advantage is that we can recover the rle information and even the
embedding vector.

It's apparent from the above that as soon as we get past the first group there
is an index mismatch.

```{r eval=FALSE}
set.seed(1)
g <- sample(seq_len(10), 95, replace=TRUE)
o <- order(g)
go <- g[o]
g.rle <- rle(go)
g.first3 <- seq_len(sum(g.rle[['lengths']][1:3]))
rbind(
  go[g.first3]
)
```


# Pedal To The Metal

Out of curiosity I wrote a version of `rowsum` that orders the data by group and
takes advantage of that to compute the group sums and counts.  Essentially, as
we can through the ordered groups, we know each time the group changes, we can
save the accumulator to the result and reset it to zero.  This ends up slightly
faster than even `data.table`.

```{r sum-timings, echo=FALSE, eval=FALSE}
sys.time({
  o <- order(grp)
  go <- grp[o]
  xo <- x[o]
  yo <- y[o]
})
```
```
   user  system elapsed
  0.936   0.019   1.000
```

Group slope `rowsum` without ordering time.

```{r eval=FALSE}
sys.time({
  tmp <- rowsum(cbind(xo, yo, rep(1, length(o))), grp[o])
  ux <- tmp[,1]/tmp[,3]
  uy <- tmp[,2]/tmp[,3]

  gi <- rep(seq_along(ux), c(tmp[,3]))
  x_ux <- xo - ux[gi]
  y_uy <- yo - uy[gi]
  gs.0 <- rowsum(x_ux * y_uy, go) / rowsum(x_ux ^ 2, go)
})
```
```
   user  system elapsed
  2.594   0.366   2.963
```
Group slope with colsums
```{r}
o_embed_dat <- function(g) {
  # g must be ordered

  g.rle <- rle(g)
  max.g <- max(g.rle[['lengths']])

  # each group that isn't as long as the longest group needs padding

  rle.len <- g.rle[['lengths']]
  g.pad <- max.g - rle.len + 1L
  idx.raw <- rep(1L, length(g))
  idx.raw[(cumsum(rle.len) + 1L)] <- g.pad
  idx <- cumsum(idx.raw[-length(idx.raw)])

  list(idx=idx, rle=g.rle)
}
ogroup_sum_cs <- function(x, embed_dat, na.rm=FALSE) {
  # x and g must be ordered
  rle.len <- embed_dat[['rle']][['lengths']]
  res <- matrix(0, ncol=length(rle.len), nrow=max(rle.len))
  res[embed_dat[['idx']]] <- x
  setNames(colSums(res, na.rm=na.rm), embed_dat[['rle']][['values']])
}
sys.time({
  ed <- o_embed_dat(go)
  lens <- ed[['rle']][['lengths']]
  ux <- ogroup_sum_cs(xo, ed)/lens
  uy <- ogroup_sum_cs(yo, ed)/lens
  gi <- rep(seq_along(ux), lens)

  x_ux <- xo - ux[gi]
  y_uy <- yo - uy[gi]
  gs.cs <- ogroup_sum_cs(x_ux * y_uy, ed) / ogroup_sum_cs(x_ux ^ 2, ed)
})
```
```
   user  system elapsed 
  1.351   0.635   1.995 
```
```{r eval=FALSE}
sys.time({
  xg <- ogroup_sum(xo, go)
  yg <- ogroup_sum(yo, go)
  gn <- attr(xg, 'grp.size')
  gi <- rep(seq_along(gn), gn)

  x_ux <- xo - (xg/gn)[gi]
  y_ux <- yo - (yg/gn)[gi]
  gs.1 <- ogroup_sum(x_ux * y_ux, go)/ogroup_sum(x_ux^2, go)
})
```
```
   user  system elapsed
  0.463   0.086   0.550
```
```{r eval=FALSE}
sys.time({
  gs.2 <- ogroup_slope(xo, yo, go)
})
```
```
   user  system elapsed
  0.067   0.000   0.067
```

Benchmark plots needed:

* rowsum vs colsum, ogroup_sum vs data.table
* slope w/ rowsum, colsum, ogroup_slope vs data.table

Placeholder plot:

```{r sum-benchmarks, echo=FALSE}
plot(1:10, 1:10)
```

# Rowsums

# colSums
```{r eval=FALSE}

x <-runif(95)




  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len


  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
```

```{r eval=FALSE}
sum_g3 <- function(x, grp, na.rm=TRUE) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  max.grp <- max(grp.rle[['lengths']])

  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len
  id.raw <- rep(1L, length(x))
  id.raw[(cumsum(rle.len) + 1L)[-length(rle.len)]] <-
    grp.pad[-length(rle.len)] + 1L
  id <- cumsum(id.raw)

  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
}
sum_g3a <- function(x, grp, na.rm=TRUE) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  max.grp <- max(grp.rle[['lengths']])

  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len + 1L
  id.raw <- rep(1L, length(x))
  id.raw[(cumsum(rle.len) + 1L)] <- grp.pad
  id <- cumsum(id.raw[-length(id.raw)])

  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
}


system.time(sum_g3(x, grp))
sys.time(sum_g3(x, grp))
sys.time(sum_g3a(x, grp))
sys.time(embed_dat(grp))
sys.time(zz <- sum_g3b(x, grp))

```
```
   user  system elapsed
  1.186   0.374   1.634
```
```{r eval=FALSE}
  # lens: how long each group is
  # maxlen: longest group
sum_grp2 <- function(x, lens, maxlen, mode='sum') {

  res <- matrix(NA_real_, ncol=length(lens), nrow=maxlen)

  # Generate indices that will map to the correct spots in `res` from `x`,
  # which means add whatever padding we need to the index value for the next
  # column

  len_1 <- lens[-length(lens)]
  grp.pad <- (maxlen + 1L) - len_1
  id.raw <- rep(1L, length(x))
  len_1[1L] <- len_1[1L] + 1L
  id.raw[cumsum(len_1)] <- grp.pad
  id <- cumsum(id.raw)

  # Inject the x values according to these indices that should place each gropu
  # in a column

  res[id] <- x

  if(identical(mode, 'sum')) colSums(res, na.rm=TRUE)
  else if(identical(mode, 'mean')) colMeans(res, na.rm=TRUE)
  else stop("Invalid mode")
}
```



# Conclusions

<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<div id='feedback-cont'></div>

# Appendix

## Data

```{r child='../../static/chunks/grp-dat.Rmd'}
```

## Functions

### sys.time

### group_sum

Similar to `rowsum`, except it returns group sizes and the group ordering vector
as attributes.  Group sizes allow us to either compute means or recycle the
result statistic back to the input length.  The ordering vector can be used on
other variables with the same grouping.

This is a limited implementation that only works for double `x` values and
relies completely on the native code to handle NA/Infinite values.  It will
ignore dimensions of matrices, and has undefined behavior if any group has more
elements than than `INT_MAX`.

Inputs must be ordered in increasing order by group, with if it exists the NA
group last.  The NA group will be treated as a single group (i.e. NA==NA is
TRUE).

```{r group_sum, eval=FALSE}
ogroup_sum <- function(x, group) {
  stopifnot(
    typeof(x) == 'double', is.integer(group), length(x) == length(group)
  )
  tmp <- .ogroup_sum(x, group)
  res <- setNames(tmp[[1]], tmp[[2]])
  attr(res, 'grp.size') <- tmp[[3]]
  res
}
.ogroup_sum <- inline::cfunction(
  sig=c(x='numeric', g='integer'),
  body="
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_n;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\"Unequal Length Vectors\");
  res = PROTECT(allocVector(VECSXP, 3));

  if(len > 1) {
    // count uniques
    for(i = 1; i < len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));
    res_n = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    int *res_gi = INTEGER(res_g);
    int *res_ni = INTEGER(res_n);
    R_xlen_t j = 0;
    R_xlen_t prev_n = 0;

    res_xi[0] = 0;
    for(i = 1; i < len; ++i) {
      res_xi[j] += xi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] < gi[i]){
        res_gi[j] = gi[i - 1];
        res_ni[j] = i - prev_n;  // this could overflow int; undefined?
        prev_n = i;
        ++j;
        res_xi[j] = 0;
      } else error(\"Decreasing group order found at index %d\", i + 1);
    }
    res_xi[j] += xi[i - 1];
    res_gi[j] = gi[i - 1];
    res_ni[j] = i - prev_n;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    SET_VECTOR_ELT(res, 2, res_n);
    UNPROTECT(3);
  } else {
    // Don't seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
")
```

### group_slope

```{r group_slope, eval=FALSE}
ogroup_slope <- function(x, y, group) {
  stopifnot(
    typeof(x) == 'double', is.integer(group), length(x) == length(group),
    typeof(y) == 'double', length(x) == length(y)
  )
  tmp <- .ogroup_slope(x, y, group)
  res <- setNames(tmp[[1]], tmp[[2]])
  res
}
.ogroup_slope <- inline::cfunction(
  sig=c(x='numeric', y='numeric',  g='integer'),
  body="
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_y;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  double *yi = REAL(y);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\"Unequal Length Vectors\");
  res = PROTECT(allocVector(VECSXP, 2));

  if(len > 1) {
    // First pass compute unique groups
    for(i = 1; i < len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_y = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    double *res_yi = REAL(res_y);
    int *res_gi = INTEGER(res_g);
    R_xlen_t j = 0;
    R_xlen_t prev_i = 0, n;

    // Second pass compute means

    double xac, yac;
    yac = xac = 0;
    for(i = 1; i < len; ++i) {
      xac += xi[i - 1];
      yac += yi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] < gi[i]){
        n = i - prev_i;
        res_xi[j] = xac / n;
        res_yi[j] = yac / n;
        res_gi[j] = gi[i - 1];
        prev_i = i;
        yac = xac = 0;
        ++j;
      } else error(\"Decreasing group order found at index %d\", i + 1);
    }
    xac += xi[i - 1];
    yac += yi[i - 1];
    n = i - prev_i;
    res_xi[j] = xac / n;
    res_yi[j] = yac / n;
    res_gi[j] = gi[i - 1];

    // third pass compute slopes

    double xtmp, ytmp;
    yac = xac = xtmp = ytmp = 0;
    j = 0;

    for(i = 1; i < len; i++) {
      xtmp = xi[i - 1] -  res_xi[j];
      ytmp = yi[i - 1] -  res_yi[j];
      xac += xtmp * xtmp;
      yac += ytmp * xtmp;

      if(gi[i - 1] == gi[i]) {
        continue;
      } else {
        res_xi[j] = yac / xac;
        yac = xac = 0;
        ++j;
      }
    }
    xtmp = xi[i - 1] -  res_xi[j];
    ytmp = yi[i - 1] -  res_yi[j];
    xac += xtmp * xtmp;
    yac += ytmp * xtmp;
    res_xi[j] = yac / xac;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    UNPROTECT(3);
  } else {
    // Don't seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
")
```

## Acknowledgments

* This blog would not exist but for amazing contributions from many ...
* Rcpp/inline

[100]: /tags/hydra/
[110]: /2019/06/10/base-vs-data-table/#group-sums
[120]: /2019/06/10/base-vs-data-table/#rowsums
[130]: /2019/05/17/pixie-dust/#loose-ends
