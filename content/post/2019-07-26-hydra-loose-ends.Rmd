---
title: "Hydra Chronicles Part V: Loose Ends"
author: ~
date: '2019-07-26'
slug: hydra-loose-ends
categories: [r]
tags: [group-stats,optim,hydra]
image: /front-img/default.png
imagerect: ~
imagemrgvt: 0%
imagemrghz: 0%
weight: 1
contenttype: article
description: Front page summary
---

```{r echo=FALSE}
options(digits=3)
knitr::opts_chunk$set(comment = "", fig.align='center', error=TRUE)
```

# Almost Done!

<!-- this needs to become a shortcode -->
<img
  id='front-img' src='/front-img/default.png'
  class='post-inset-image'
/>

Fingers crossed this will be the last post of the [Hydra Chronicles][100], a.k.a.
"Everything You Didn't Want To Know About Group Statistics But Let Me Tell You
Anyway".  Well, it's more of an end note rather than a real post: a few tidbits
that ended up on the cutting floor in the earlier posts.

One of our early "discoveries" about group statistics is that if we can compute
the group sum, we can build on that to compute many other group statistics.
We'll go over here a few of the other strategies I tested out before I settled
on the [`cumsum` based approach][110] we used to "beat" `data.table`.

# rowsum

I did mention this one [in passing][120], but it bears re-examining:
`base::rowsum` is a remarkable creature in the base R ecosystem.  As far as I
know, it is the only R function that can compute group statistics on unequal
group sizes in native code.  Despite that, it feels like a relatively
unknown function.  In my own experience, I've seen infinitely more uses of
`base::rowSums` than `base::rowsum`.  As you might imagine my attempts to get
firmer evidence from search engines was fruitless.  Perhaps `rowsum` hides
from others behind the shadow of the capitalization and pluralization of
`rowSums`, as it did for many years for me.  Or maybe I'm just the idiot that
missed The Memo.

In the spirit of a code snippet is worth a thousand words, and using our beaten
to death 10MM row, ~1MM group [data set](#data):

```{r eval=FALSE}
sys.time(gsum.0 <- tapply(x, grp, sum))
```
```
   user  system elapsed 
  6.956   0.112   7.107 
```
```{r eval=FALSE}
sys.time(gsum.1 <- rowsum(x, grp))
```
```
   user  system elapsed 
  2.359   0.048   2.430 
```

`sys.time` is a [wrapper around `system.time` defined in the
appendix](#sys-time).

```{r eval=FALSE}
all.equal(c(gsum.0), c(gsum.1), check.attributes=FALSE)
```

`rowsum` provides similar functionality to `tapply(..., sum)` (or equivalently,
`vapply(split(...), sum, 0)` with a single grouping variable, but with a
noticeable speed-up as it can avoid the per-group R-level calls.  Speed is
improved even when pre-ordering the inputs, although the difference between the
methods is similar as the ordering becomes a substantial portion of the overall
run time.  `data.table` and the "Gforce" optimized sum remain ahead:

```{r}

```

Even so `rowsum` is sub-optimal because internally it uses a hash table, which
is [inefficient with ordered data][130].  It also does not return the group
sizes which is something we are likely to want when computing more complex
statistics.  Certainly we could compute them with a vector of ones, but that
requires an additional run.

Out of curiosity I wrote a version of `rowsum` that :



Inevitably there were some thing I cut
Right now my plan is to throw in all the couple of random things I ended up
removing from prior posts for the sake of streamlining them, but that I find too
interesting to leave completely unmentioned.

# Rowsums

# colSums

```{r eval=FALSE}
sum_g3 <- function(x, grp, na.rm=TRUE) {
  ord <- order(grp)
  id.ord <- id[ord]
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  max.grp <- max(grp.rle[['lengths']])

  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len
  id.raw <- rep(1L, length(x))
  id.raw[(cumsum(rle.len) + 1L)[-length(rle.len)]] <-
    grp.pad[-length(rle.len)] + 1L
  id <- cumsum(id.raw)

  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
}
system.time(sum_g3(x, grp))
```
```
   user  system elapsed
  1.186   0.374   1.634
```
```{r eval=FALSE}
  # lens: how long each group is
  # maxlen: longest group
sum_grp2 <- function(x, lens, maxlen, mode='sum') {

  res <- matrix(NA_real_, ncol=length(lens), nrow=maxlen)

  # Generate indices that will map to the correct spots in `res` from `x`,
  # which means add whatever padding we need to the index value for the next
  # column

  len_1 <- lens[-length(lens)]
  grp.pad <- (maxlen + 1L) - len_1
  id.raw <- rep(1L, length(x))
  len_1[1L] <- len_1[1L] + 1L
  id.raw[cumsum(len_1)] <- grp.pad
  id <- cumsum(id.raw)

  # Inject the x values according to these indices that should place each gropu
  # in a column

  res[id] <- x

  if(identical(mode, 'sum')) colSums(res, na.rm=TRUE)
  else if(identical(mode, 'mean')) colMeans(res, na.rm=TRUE)
  else stop("Invalid mode")
}
```

other random 


# Conclusions

<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<div id='feedback-cont'></div>

# Appendix

### Data

```{r child='../../static/chunks/grp-dat.Rmd'}
```

## Acknowledgments

* This blog would not exist but for amazing contributions from many ...

[100]: /tags/hydra/
[110]: /2019/06/10/base-vs-data-table/#group-sums
[120]: /2019/06/10/base-vs-data-table/#rowsums
[130]: /2019/05/17/pixie-dust/#loose-ends
