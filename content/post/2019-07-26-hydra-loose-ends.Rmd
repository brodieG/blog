---
title: "Hydra Chronicles Part V: Loose Ends"
author: ~
date: '2019-07-26'
slug: hydra-loose-ends
categories: [r]
tags: [group-stats,optim,hydra]
image: /front-img/default.png
imagerect: ~
imagemrgvt: 0%
imagemrghz: 0%
weight: 1
contenttype: article
description: Front page summary
---

```{r echo=FALSE}
options(digits=3)
knitr::opts_chunk$set(comment = "", fig.align='center', error=TRUE)
```

# Almost Done!

<!-- this needs to become a shortcode -->
<img
  id='front-img' src='/front-img/default.png'
  class='post-inset-image'
/>

Fingers crossed this will be the last post of the [Hydra Chronicles][100], a.k.a.
"Everything You Didn't Want To Know About Group Statistics But Let Me Tell You
Anyway".  Well, it's more of an end note rather than a real post: a few tidbits
that ended up on the cutting floor in the earlier posts.

One of our early "discoveries" about group statistics is that if we can compute
the group sum, we can build on that to compute many other group statistics.
We'll go over here a few of the other strategies I tested out before I settled
on the [`cumsum` based approach][110] we used to "beat" `data.table`.

# rowsum

I did mention this one [in passing][120], but it bears re-examining:
`base::rowsum` is a remarkable creature in the base R ecosystem.  As far as I
know, it is the only R function that can compute group statistics on unequal
group sizes in native code.  Despite that, it feels like a relatively
unknown function.  In my own experience, I've seen infinitely more uses of
`base::rowSums` than `base::rowsum`.  As you might imagine my attempts to get
firmer evidence from search engines was fruitless.  Perhaps `rowsum` hides
from others behind the shadow of the capitalization and pluralization of
`rowSums`, as it did for many years for me.  Or maybe I'm just the idiot that
missed The Memo.

In the spirit of a code snippet is worth a thousand words, and using our beaten
to death 10MM row, ~1MM group [data set](#data):

```{r eval=FALSE}
sys.time(gsum.0 <- tapply(x, grp, sum))
```
```
   user  system elapsed 
  6.956   0.112   7.107 
```
```{r eval=FALSE}
sys.time(gsum.1 <- rowsum(x, grp))
```
```
   user  system elapsed 
  2.359   0.048   2.430 
```

`sys.time` is a [wrapper around `system.time` defined in the
appendix](#sys-time).

```{r eval=FALSE}
all.equal(c(gsum.0), c(gsum.1), check.attributes=FALSE)
```

`rowsum` provides similar functionality to `tapply(..., sum)` (or equivalently,
`vapply(split(...), sum, 0)` with a single grouping variable, but with a
noticeable speed-up as it can avoid the per-group R-level calls.  Speed is
improved even when pre-ordering the inputs, although the difference between the
methods is similar as the ordering becomes a substantial portion of the overall
run time.

Even so `rowsum` is sub-optimal because internally it uses a hash table, which
is [inefficient with ordered data][130].  It also does not return the group
sizes which could easily be computed along the sums and we are likely to want
when computing more complex statistics.

# ColSums

```
xx <- matrix(runif(2000*2000), 2000)
sys.time(rowSums(xx))
sys.time(colSums(xx))
```
```{r}
set.seed(1)
gn <- 10
g <- sample(seq_len(gn), 95, replace=TRUE)
levels <- c('start', 'order', 'longest', 'nrow', 'allocate', 'embed', 'colSums')
dat10 <- data.frame(
  step='start', id=seq_along(g), g,
  x=(seq_along(g) - 1) %/% 10, y=-((seq_along(g) - 1) %% 10),
  alpha=1, label=0, stringsAsFactors=FALSE
)
dat20 <- transform(
  dat10[order(g),],
  step='order', x=(seq_along(g) - 1) %/% 10, y=-((seq_along(g) - 1) %% 10)
)

g.rle <- with(dat20, rle(g))

dat30 <- transform(
  dat20, step='longest',
  alpha=ifelse(g==g.rle[['values']][which.max(g.rle[['lengths']])], 1, .2)
)
g.max <- nrow(subset(dat30, alpha==1))
dat30 <- rbind(
  dat30,
  transform(subset(dat30, alpha==1), g=NA, label=1)
)
dat30 <- rbind(
  subset(dat30, label==0),
  transform(
    subset(dat30, label==1), x=gn + 1, y=-(seq_along(y) - 1)
  )
)
dat30 <- do.call(
  rbind,
  c(
    list(dat30),
    replicate(gn - 1L, subset(dat30, label==1), simplify=FALSE)
) )
dat50 <- transform(
  rbind(
    dat30,
    transform(subset(dat30, label==0), label=2)
  ),
  step='allocate',
  alpha=1
)
dat50[dat50[['label']] == 1,] <- transform(
  subset(dat50, label == 1),
  x=rep((seq_len(gn)) + gn, each=g.max)
)
dat60 <- transform(
  rbind(
    subset(dat50, label == 1),
    transform(subset(dat50, label == 0), g=NA),
    transform(
      subset(dat50, label==2), x=gn + g, y=-sequence(g.rle[['lengths']]) + 1
    )
  ),
  step='embed'
)
dat70 <- transform(
  rbind(
    subset(dat60, label %in% 0:1),
    transform(subset(dat60, label == 2), y=0)
  ),
  step='colSums'
)
dat <- transform(
  rbind(dat10, dat20, dat30, dat50, dat60, dat70),
  step=factor(step, levels=levels)
)

ggplot(dat) +
  geom_tile(aes(x, y, fill=g, alpha=alpha), color='#AAAAAA') +
  scale_fill_viridis_c(guide=FALSE, na.value='#F3F3F3') +
  scale_alpha(guide=FALSE, range=c(0.3,1)) +
  theme(
    panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
    axis.title.x=element_blank(), axis.text.x=element_blank(),
    axis.ticks.x=element_blank(),
    axis.title.y=element_blank(), axis.text.y=element_blank(),
    axis.ticks.y=element_blank()
  ) +
  transition_states(step)
```


# Pedal To The Metal

Out of curiosity I wrote a version of `rowsum` that orders the data by group and
takes advantage of that to compute the group sums and counts.  Essentially, as
we can through the ordered groups, we know each time the group changes, we can
save the accumulator to the result and reset it to zero.  This ends up slightly
faster than even `data.table`.

```{r sum-timings, echo=FALSE}
sys.time({
  o <- order(grp)
  go <- grp[o]
  xo <- x[o]
  yo <- y[o]
})
```
```
   user  system elapsed 
  0.936   0.019   1.000 
```
```{r}
sys.time({
  tmp <- rowsum(cbind(xo, yo, rep(1, length(o))), grp[o])
  ux <- tmp[,1]/tmp[,3]
  uy <- tmp[,2]/tmp[,3]

  gi <- rep(seq_along(ux), c(tmp[,3]))
  x_ux <- xo - ux[gi]
  y_uy <- yo - uy[gi]
  gs.0 <- rowsum(x_ux * y_uy, go) / rowsum(x_ux ^ 2, go)
})
```
```
   user  system elapsed 
  2.594   0.366   2.963 
```
```{r}
sys.time({
  xg <- ogroup_sum(xo, go)
  yg <- ogroup_sum(yo, go)
  gn <- attr(xg, 'grp.size')
  gi <- rep(seq_along(gn), gn)

  x_ux <- xo - (xg/gn)[gi]
  y_ux <- yo - (yg/gn)[gi]
  gs.1 <- ogroup_sum(x_ux * y_ux, go)/ogroup_sum(x_ux^2, go)
})
```
```
   user  system elapsed 
  0.463   0.086   0.550 
```
```{r}
sys.time({
  gs.2 <- ogroup_slope(xo, yo, go)
})
```
```
   user  system elapsed 
  0.067   0.000   0.067 
```

Inevitably there were some thing I cut
Right now my plan is to throw in all the couple of random things I ended up
removing from prior posts for the sake of streamlining them, but that I find too
interesting to leave completely unmentioned.

# Rowsums

# colSums

```{r eval=FALSE}
sum_g3 <- function(x, grp, na.rm=TRUE) {
  ord <- order(grp)
  id.ord <- id[ord]
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  max.grp <- max(grp.rle[['lengths']])

  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len
  id.raw <- rep(1L, length(x))
  id.raw[(cumsum(rle.len) + 1L)[-length(rle.len)]] <-
    grp.pad[-length(rle.len)] + 1L
  id <- cumsum(id.raw)

  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
}
system.time(sum_g3(x, grp))
```
```
   user  system elapsed
  1.186   0.374   1.634
```
```{r eval=FALSE}
  # lens: how long each group is
  # maxlen: longest group
sum_grp2 <- function(x, lens, maxlen, mode='sum') {

  res <- matrix(NA_real_, ncol=length(lens), nrow=maxlen)

  # Generate indices that will map to the correct spots in `res` from `x`,
  # which means add whatever padding we need to the index value for the next
  # column

  len_1 <- lens[-length(lens)]
  grp.pad <- (maxlen + 1L) - len_1
  id.raw <- rep(1L, length(x))
  len_1[1L] <- len_1[1L] + 1L
  id.raw[cumsum(len_1)] <- grp.pad
  id <- cumsum(id.raw)

  # Inject the x values according to these indices that should place each gropu
  # in a column

  res[id] <- x

  if(identical(mode, 'sum')) colSums(res, na.rm=TRUE)
  else if(identical(mode, 'mean')) colMeans(res, na.rm=TRUE)
  else stop("Invalid mode")
}
```

other random 


# Conclusions

<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<div id='feedback-cont'></div>

# Appendix

## Data

```{r child='../../static/chunks/grp-dat.Rmd'}
```

## Functions

### sys.time

### group_sum

Similar to `rowsum`, except it returns group sizes and the group ordering vector
as attributes.  Group sizes allow us to either compute means or recycle the
result statistic back to the input length.  The ordering vector can be used on
other variables with the same grouping.

This is a limited implementation that only works for double `x` values and
relies completely on the native code to handle NA/Infinite values.  It will
ignore dimensions of matrices, and has undefined behavior if any group has more
elements than than `INT_MAX`.

Inputs must be ordered in increasing order by group, with if it exists the NA
group last.  The NA group will be treated as a single group (i.e. NA==NA is
TRUE).

```{r group_sum, eval=FALSE}
ogroup_sum <- function(x, group) {
  stopifnot(
    typeof(x) == 'double', is.integer(group), length(x) == length(group)
  )
  tmp <- .ogroup_sum(x, group)
  res <- setNames(tmp[[1]], tmp[[2]])
  attr(res, 'grp.size') <- tmp[[3]]
  res
}
.ogroup_sum <- inline::cfunction(
  sig=c(x='numeric', g='integer'),
  body="
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_n;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\"Unequal Length Vectors\");
  res = PROTECT(allocVector(VECSXP, 3));

  if(len > 1) {
    // count uniques
    for(i = 1; i < len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));
    res_n = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    int *res_gi = INTEGER(res_g);
    int *res_ni = INTEGER(res_n);
    R_xlen_t j = 0;
    R_xlen_t prev_n = 0;

    res_xi[0] = 0;
    for(i = 1; i < len; ++i) {
      res_xi[j] += xi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] < gi[i]){
        res_gi[j] = gi[i - 1];
        res_ni[j] = i - prev_n;  // this could overflow int; undefined?
        prev_n = i;
        ++j;
        res_xi[j] = 0;
      } else error(\"Decreasing group order found at index %d\", i + 1);
    }
    res_xi[j] += xi[i - 1];
    res_gi[j] = gi[i - 1];
    res_ni[j] = i - prev_n;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    SET_VECTOR_ELT(res, 2, res_n);
    UNPROTECT(3);
  } else {
    // Don't seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
")
```

### group_slope

```{r group_slope, eval=FALSE}
ogroup_slope <- function(x, y, group) {
  stopifnot(
    typeof(x) == 'double', is.integer(group), length(x) == length(group),
    typeof(y) == 'double', length(x) == length(y)
  )
  tmp <- .ogroup_slope(x, y, group)
  res <- setNames(tmp[[1]], tmp[[2]])
  res
}
.ogroup_slope <- inline::cfunction(
  sig=c(x='numeric', y='numeric',  g='integer'),
  body="
  R_xlen_t len, i, len_u = 1;
  SEXP res, res_x, res_g, res_y;
  int *gi = INTEGER(g);
  double *xi = REAL(x);
  double *yi = REAL(y);
  len = XLENGTH(g);
  if(len != XLENGTH(x)) error(\"Unequal Length Vectors\");
  res = PROTECT(allocVector(VECSXP, 2));

  if(len > 1) {
    // First pass compute unique groups
    for(i = 1; i < len; ++i) {
      if(gi[i - 1] != gi[i]) {
        ++len_u;
    } }
    // allocate and record uniques
    res_x = PROTECT(allocVector(REALSXP, len_u));
    res_y = PROTECT(allocVector(REALSXP, len_u));
    res_g = PROTECT(allocVector(INTSXP, len_u));

    double *res_xi = REAL(res_x);
    double *res_yi = REAL(res_y);
    int *res_gi = INTEGER(res_g);
    R_xlen_t j = 0;
    R_xlen_t prev_i = 0, n;

    // Second pass compute means

    double xac, yac;
    yac = xac = 0;
    for(i = 1; i < len; ++i) {
      xac += xi[i - 1];
      yac += yi[i - 1];
      if(gi[i - 1] == gi[i]) {
        continue;
      } else if (gi[i - 1] < gi[i]){
        n = i - prev_i;
        res_xi[j] = xac / n;
        res_yi[j] = yac / n;
        res_gi[j] = gi[i - 1];
        prev_i = i;
        yac = xac = 0;
        ++j;
      } else error(\"Decreasing group order found at index %d\", i + 1);
    }
    xac += xi[i - 1];
    yac += yi[i - 1];
    n = i - prev_i;
    res_xi[j] = xac / n;
    res_yi[j] = yac / n;
    res_gi[j] = gi[i - 1];

    // third pass compute slopes

    double xtmp, ytmp;
    yac = xac = xtmp = ytmp = 0;
    j = 0;

    for(i = 1; i < len; i++) {
      xtmp = xi[i - 1] -  res_xi[j];
      ytmp = yi[i - 1] -  res_yi[j];
      xac += xtmp * xtmp;
      yac += ytmp * xtmp;

      if(gi[i - 1] == gi[i]) {
        continue;
      } else {
        res_xi[j] = yac / xac;
        yac = xac = 0;
        ++j;
      }
    }
    xtmp = xi[i - 1] -  res_xi[j];
    ytmp = yi[i - 1] -  res_yi[j];
    xac += xtmp * xtmp;
    yac += ytmp * xtmp;
    res_xi[j] = yac / xac;

    SET_VECTOR_ELT(res, 0, res_x);
    SET_VECTOR_ELT(res, 1, res_g);
    UNPROTECT(3);
  } else {
    // Don't seem to need to duplicate x/g
    SET_VECTOR_ELT(res, 0, x);
    SET_VECTOR_ELT(res, 1, g);
    SET_VECTOR_ELT(res, 2, PROTECT(allocVector(REALSXP, 0)));
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return res;
")
```

## Acknowledgments

* This blog would not exist but for amazing contributions from many ...
* Rcpp/inline

[100]: /tags/hydra/
[110]: /2019/06/10/base-vs-data-table/#group-sums
[120]: /2019/06/10/base-vs-data-table/#rowsums
[130]: /2019/05/17/pixie-dust/#loose-ends
