---
title: Quosures
author: ~
date: '2020-02-17'
slug: quosures
categories: [r]
tags: [meta-program,rlang]
image: /front-img/default.png
imagerect: ~
imagemrgvt: 0%
imagemrghz: 0%
weight: 1
contenttype: article
description: Front page summary
output:
  blogdown::html_page:
    keep_md: yes
    md_extensions: +raw_attribute
---
```{r echo=FALSE, child='../../static/chunks/init.Rmd'}
```

# Quosures?

Quosures first showed up on the scene as part of `rlang` about three years ago
to a collective &#x1F92F;.  There is good and bad &#x1F92F;, and quosures
delivered both in spades.  The good: what they do is powerful, and how they do
it at a minimum _seems_ magical.  The bad: new terminology and mechanics
confused a lot of people.  Since then the developers have devoted substantial
time and effort to make quosures and `rlang` in general more accessible.

There are two obvious reasons to introduce new terminology: the existing
terminology is bad, or there are new features that cannot be expressed in the
old terminology.  Certainly the existing terminology is imperfect, and `rlang`
brings along many interesting new concepts.  But I also believe it is better to
enhance flawed-but-workable precedents than unilaterally create Standard
Sixteen.

<!-- CC BY SA 2.5 -->
<img src='https://imgs.xkcd.com/comics/standards.png' />

# Preface: Carriages, Horses, and Damn Philosophers...

## Ghosts of Posts Past

If you are unfamiliar with R's evaluation model, and how it enables
"Non-Standard Evaluation" (NSE), now is a good time to check out last week's
[post on the topic][1].  To understand this post it might help to know what
environments, "Enclosures" and "Environment Chains" are, the difference between
"Evaluation", "Calling", "Function", and "function Evaluation" Environments, and
what unevaluated commands are and how they are created.  All these are discussed
at length in that post.

## Quasi-quoi?

As we saw previously it is possible to capture unevaluated R commands with
[`quote` and `substitute`][3].  We can also manipulate them:

```{r}
mean_call <- function(cmd) {
  cmd2 <- quote(mean(NULL))     # create unevaled `mean(NULL)`
  cmd2[[2]] <- substitute(cmd)  # sub in user expression
  cmd2
}
mean_call(a + b)
```

The manipulation is awkward though.  Thankfully R provides `bquote` to
partially quote commands (or partially evaluate them, depending on your life
outlook - I'm more of a command-half-evaluated guy).  Let's look
first at a trivial example:

```{r}
bquote(mean(.(1 + 2)))
```

Compare to:

```{r}
quote(mean(1 + 2))
```

`quote` captures the entire command unevaluated.  `bquote` allows whatever is
inside the `.(...)` to be evaluated.  We can use `bquote` to recreate
`mean_call`:

```{r}
mean_call2 <- function(cmd) {
  bquote(mean(.(substitute(cmd))))
}
mean_call2(a + b)
```

Wait, but that's an unevaluated call.  Didn't we promise partial evaluation?  We
delivered, but it's not obvious because what was partially evaluated,
`substitute(cmd)`, produced an unevaluated command.  We can see that by
comparing to an implementation that uses `quote` instead of `bquote`:

```{r}
mean_call2a <- function(cmd) {
  quote(mean(substitute(cmd)))
}
mean_call2a(a + b)
mean_call2(a + b)
```

In this case we can see that `quote` does not evaluate `substitute(cmd)`,
whereas `bquote` does.

How does this all relate to quasi-quotation?  Turns out partial evaluation
**is** quasi-quotation.  It's just that [quasi-quotation][4] was coined by the
philosopher [Willard Van Orman Quine][5], and without arcaneness it would not be
philosophy[^resentment].  Lisp adopted the terminology, `rlang` brought it
explicitly to R, and the rest of us were left to scratch our heads.

So what's the etymology of R's `bquote`?  Turns out that in certain Lisp
dialects such as Scheme the equivalent to the R `quote` function is a single
quote `'`, and quasi-quoting (partial evaluation) is done with
the "backquote" <code>&#x60;</code>.  So R's quasi-quoting function is named
after the name of the <code>&#x60;</code>.  I suspect a fair bit of confusion
among R users could have been avoided simply by riffing off of the "backquote"
terminology, even though "quasi-quote" is strictly more correct.

More recently `rlang` has shifted to different terminology.  While it's
great the `rlang` team has responded to feedback and tried to adapt it would
have been nice to see a re-convergence towards existing R terminology rather
than toward Standard Seventeen.

## Eat `local`

One last thing before we get going for real.  In order to stress test quosures
and related elements we need to construct interesting Evaluation Environments.
R provides the `local` function as a mechanism for doing exactly this:

```{r}
a <- 1
num <- 2
local({
  a <- 100
  a + num
})
a + num
```

The `a` defined at the top-level (`a <- 1`) is masked by the one defined
inside the `local` Evaluation Environment (`a <- 100`), but only for commands
evaluated in that environment.  This is akin to how commands in function bodies
are evaluated in function Evaluation Environments.

We'll be using `local` to create interesting ad-hoc evaluation contexts.

# About Them Quosures

Just as `quote`, `substitute`, and `bquote`  do, quosures capture unevaluated
R commands.

```{r}
library(rlang)
a <- 1
(qrlang <- quo(a + 1))   # create a quosure with quo
```

Additionally as you can see above, quosures record the environment the command
would have been evaluated in, had it not been captured.  Unlike typical
unevaluated commands, quosures do no resolve when the are `eval`ed:

```{r}
eval(qrlang)
```

We'll see why this is in a little bit, but until then we can use `eval_tidy` to
evaluate quosures:

```{r}
eval_tidy(qrlang)
```

Things are more interesting with more complex environments.  Let's compare
commands captured with `quote` vs `quo` in an ad-hoc environment created with
[`local`](#interlude-local):

```{r}
a <- 1
lang <- local({
  a <- 100
  list(
    base=quote(a + 1),
    rlang=quo(a + 1)
  )
})
eval(lang[['base']])
eval_tidy(lang[['rlang']])
```

Normal quoted language resolves `a` in the environment in which it is
`eval`ed.  The quosure instead resolves `a` in the Evaluation Environment in
which it was **created**.  Pretty neat.

# Quosures in Functions

Let's build a simple NSE function to compute means in the context of of a
user-supplied data frame.  First with base:

```{r}
mean_with_base <- function(dat, cmd) {
  cmd <- substitute(cmd)           # capture user command
  cmd <- bquote(mean(.(cmd)))      # wrap it in `mean`
  eval(cmd, dat, parent.frame())
}
```

We'll use it to compute mean engine displacement of `mtcars` in liters:

```{r}
l.per.cubic.i <- 2.54^3 / 1000
mean_with_base(mtcars, disp * l.per.cubic.i)
```

Before we proceed, let's protect our function from interference by user defined
objects.  Consider:

```{r}
bquote <- function(...) stop('cool!')
mean_with_base(mtcars, disp * l.per.cubic.i)
```

**Not** cool.  Normally we would create a package with our function in it, but
that's too complicated for a silly blog post.  Instead, we'll just use an
environment to play (part) of the role of a package
namespace[^namespace-kinda]:

```{r}
pkg <- new.env(parent=base_env())  # Base only!
environment(mean_with_base) <- pkg
mean_with_base(mtcars, disp * l.per.cubic.i)
```

Now our function is shielded from user objects in the global environment.

Next with `rlang`:

```{r}
mean_with_rlang <- function(dat, cmd) {
  cmd <- enquo(cmd)                # capture user command
  cmd <- quo(mean(!!cmd))          # wrap it in `mean`
  eval_tidy(cmd, dat)
}
environment(mean_with_rlang) <- getNamespace('rlang')
mean_with_rlang(mtcars, disp * l.per.cubic.i)
```

Unfortunately the `rlang` team prioritized their own vision for a
meta-programming interface over harmonizing with existing conventions and
lexicon, so we must translate:

* `rlang::enquo` is used similarly to `base::substitute`, but bears no relation
  to `base::enquote` despite the name.
* `rlang::quo` is used similarly to `base::bquote` despite being lexically
  closer to `base::quote`.
* `rlang` designates partial evaluation with `!!` instead of `.()` as in base.

There are reasonable arguments for why things ended up how they
did[^mostly-reasonable].  I know the `rlang` team devoted a lot of time and
effort coming up with names, including trying to work with precedent.  But when
I look at the result I can't help but think the balance of priorities is off.
Obviously this is my opinion, but getting it is the risk you take when you
visit my blog.

So why bother with `rlang`, if all I'm going to do is bitch and moan about
function names?  Well, along with the lexical malpractice (I kid, I kid) we get
some very interesting features.

# The Power Of Quosures

Bad NSE implementations often break when all the referenced names in commands are not in the global environment.  Let's add a bad version of `l.per.cubic.i`
to the global environment to see if our functions find the correct version in
the Calling Environment:

```{r}
l.per.cubic.i <- NA
local({
  l.per.cubic.i <- 2.54^3 / 1000
  list(
    base=mean_with_base(mtcars, disp * l.per.cubic.i),
    rlang=mean_with_rlang(mtcars, disp * l.per.cubic.i)
  )
})
```

So far so good, but in R everything is fair game so let's take it a step further
by creating a decoy `mean` in the Calling Environment.  We purposefully set up
our functions so that the commands therein would be shielded from interference
by functions defined in the global environment, yet:

```{r}
l.per.cubic.i <- NA
local({
  mean <- function(...) 42
  l.per.cubic.i <- 2.54^3 / 1000
  list(
    base=mean_with_base(mtcars, disp * l.per.cubic.i),
    rlang=mean_with_rlang(mtcars, disp * l.per.cubic.i)
  )
})
```

The trick that allowed us to find `l.per.cubic.i` in the Calling Environment
trips us up.  We explicitly bypass `mean_with_base`'s Evaluation Environment and
in so doing lose the shield against conflicting function definitions.  `rlang`'s
version on the other hand works fine.  Ultimately the issue is that in the
command generated by `mean_with_*`:

<pre><code><span style='background-color: #aaffaa;'>mean</span>(<span
style='background-color: #aaaaff;'>disp * l.per.cubic.i</span>)</code></pre>

We need <code style='background-color: #aaffaa;'>mean</code> to be resolved
according to the Function Environment, but <code style='background-color:
#aaaaff;'>disp * l.per.cubic.i</code> in the Calling Environment.  R, however,
does not allow more than one Environment Chain at a time.

With quosures it works fine right out of the box.  Of course we can fix the R
version by pre-resolving `mean` as we did in [the prior post][2], but that's
extra work.  What sorcery allows `quosures` to evaluate a single command in
multiple environments, when R itself does not allow it?

# Is It Magic?

Let's peel the curtain back a bit:

```{r}
class(quo(a + b))
unclass(quo(a + b))
```

Quosures are formulas, which we can see both from the class, and also from the
tilde (`~`), once we side-step the quosure print method.  Formulas are an odd
duck in the R world: a form of self-quoting command that also captures the
Evaluation Environment in which it is created.  Mostly they are used to
implement domain specific languages such as model or plot specifications.
Because they can contain arbitrary R commands as well as environments they are
appealing as a vehicle for quosures.

They do have a big draw-back for our purpose: the quoting is triggered by the
`~`, but the `~` remains in the captured command:

```{r}
~a + b
```

This means you cannot evaluate the captured command as evaluating it just leads
to the command quoting itself again!  It's like those awful trick candles you
just can't blow out:

```{r}
eval(~a + b)
```

`eval_tidy` does something quite clever to force evaluation: it replaces `~`
with an internal version that self-evaluates quosures.  Here is a
hack-implementation to demonstrate the concept:

```{r}
eval_tidyish <- function(cmd) {
  env <- new.env(parent=parent.frame())
  env[['~']] <- function(...) {# replace `~` with our version
    call <- sys.call()
    env <- environment(call)   # recover formula env from call
    eval(call[[2]], env)
  }
  eval(cmd, env)
}
```

`eval_tidyish` creates an environment that contains a self-evaluating version of
`~`, and evaluates the command therein.  We can recover the formula environment
from the call to the formula, which is fortunate as otherwise this trick would
not work.  Let's try it:

```{r}
a <- 666
q1 <- local({
  a <- 42
  ~ a + 1
})
q1
eval_tidyish(q1)
```

With more emotion:

```{r echo=FALSE}
old.opt <- options(digits=4)
```
```{r}
q2 <- local({
  a <- 10
  ~ a * 43
})
bquote(.(q1) / .(q2))
eval_tidyish(bquote(.(q1) / .(q2)))
eval_tidyish(bquote(.(q1) / .(q2) + a))
```
```{r echo=FALSE}
options(old.opt)
```

Half-assed quosures!  These don't even support adding data to the Environment
Chain, deity-forbid using a formula as a _formula_, and they'll give you a
severe case of operator-precedence-anxiety.  But we do bottle that
multiple-Environment-Chain magic in a handful of lines of code.

# Natural Quosures

Formulas seem like a natural fit for quosure-like objects, but they are not.
Their resistance to evaluation is a terrible trait.  It requires a custom
evaluator along with a additional logic to preserve non-quosure `~` behavior,
which even then remains subtly affected[^subtly-affected].  There is also the
recovery of the formula environment from the call stack, which works but feels a
bit uncomfortable to me[^uncomfortable].

But R doesn't offer any other functions that hold unevaluated command and
Enclosures, so what are we to do?  Let's cheat.

In the previous post we [solved the two Environment Chain dilemma][2] by
pre-resolving the function along one Environment Chain and embedding the result
in the otherwise unevaluated command.  The key learning is that it is possible
to embed non-language objects in commands.  It's not even really cheating.  R
does this as it evaluates commands, evaluating leaves in the command tree until
the tree is fully evaluated and the result is returned.

Which leads us to:

```{r}
withq <- function(x) {
  env <- parent.frame()  # we cannot embed this below
  bquote(with(.(env), .(substitute(x))))
}
withq(a + 1)
```

What the hell is that?  It's an unevaluated call to `with` with an
alive-and-kicking environment embedded as the `data` argument.  That means that
when we evaluate the command, the provided sub-command will be evaluated in the
context of that environment.  Let's try it out:

```{r}
a <- 666
q1 <- local({
  print(environment())
  a <- 42
  withq(a + 1)
})
q1
eval(q1)
```

Boom!  We successfully captured the `a <- 42` from the local environment, even
though we evaluated the command in the top-level environment where the mapping
is `a <- 666`.

Let's up the difficulty:

```{r echo=FALSE}
old.opt <- options(digits=4)
```
```{r}
q2 <- local({
  a <- 10
  withq(a * 43)
})
(q3 <- bquote(.(q1) / .(q2)))
eval(q3)
```

Each of the `a`'s is resolved in it's own environment.  We can even mix them
with normal unevaluated commands.  The names outside of the `with`s resolve in
the Evaluation Environment:

```{r}
(q4 <- bquote(.(q1) / .(q2) + a))
eval(q4)
```
```{r echo=FALSE}
options(old.opt)
```

But, we have quosures already, why bother with this madness?  Well, it's fun.
And the `with` approach has benefits:

* We can use good-old `base::eval`; this is a big deal as it avoids a huge
  amount of complexity.
* Semantics are pure; everything behaves exactly the same way it would outside
  of `withq`.
* Complete interoperability with existing meta-programming constructs (e.g.
  `bquote`).
* WYSIWYG: the semantics of the commands are transparent.  Any useR familiar
  with `with` knows what the commands will do.  Sure, they don't necessarily
  know what's in the environments, but that's true of quosures too.
* WYSIWYG 2: We don't need any special print methods, and operator precedence is
  crystal-clear.

All of this in two lines of code!  Yes, some will object to the aesthetics of
the `with` calls everywhere, preferring the more demure `^` prefix, but the
latter relies on custom print methods which will cause confusion when they are
defeated by things such as:

```{r}
q5 <- local(quo(a + 1))
rlang::expr(a + !!q5)
```

Of course, we're not even close to replacing the full `rlang` functionality with
this, but it's not a bad start.

<!-- test passing of parameters -->
```{r}
f <- function(x) g(x)
g <- function(y) h({{y}})
h <- function(z) enquo(z)
a <- 5
f(a)

```

# Bells, Whistles

## Backquoting

An obvious missing feature is backquoting (a.k.a. quasi-quotation /
partial-evaluation).  We'll implement it as `withbq`:

```{r withbq, echo=FALSE}
withbq <- function(x) {
  env <- parent.frame()
  exp <- eval(bquote(.(bquote)(.(substitute(x)))), env)
  bquote(with(.(env), .(exp)))
}
```
```{r}
a <- 666
q5 <- local({
  q <- withbq(a + .(a))
  a <- 42   # assign to `a` AFTER withbq!
  q
})
q5
eval(q5)
```

We need to assign to `a` in `local` after the call to `withbq` as otherwise the
partially evaluated `a` would be the `local` `a` and not the global one.

The implementation is tricky:

```{r withbq, eval=FALSE}
```

There is certainly some not-so-good &#x1F92F; going on.  I can feel my brain
leaking out of my ears when I look at it and I  wrote the bloody thing.  But
that is an **implementation detail**.  Users of the function need not worry
about it, but if you're interested there is a breakdown in the appendix.

## Masking

One of the most common uses of NSE is to allow user data, usually in the form of
a data frame, to "mask" names in the Evaluation Chain.  This is typically done
by turning the data into an environment with the previous Evaluation Chain as
the Enclosure, and evaluating commands therein.  So let's do just that:

```{r}
mask <- function(cmd, dat) {
  if(is.language(cmd) && length(cmd) > 1L) {
    # modify `with` commands that contain a live environment
    if(cmd[[1L]] == as.name('with') && is.environment(cmd[[2L]])) {
      cmd[[2L]] <- list2env(dat, parent=cmd[[2L]])
    }
    # recurse on each sub-command
    cmd[2L:length(cmd)] <- lapply(cmd[2L:length(cmd)], mask, dat)
  }
  cmd
}
```

R commands are nested lists of sub-commands, and our quoted `with` statements
are unevaluated R commands.   Most of the function recurses through those lists.
The key line is:

```{r eval=FALSE}
      cmd[[2L]] <- list2env(mask, parent=cmd[[2L]])
```

There we use the existing environment as the Enclosure to the data mask, and
then we swap the data mask in.  Let's try it:

```{r}
q6 <- local({
  a <- 42
  withq(a + b + 1)
})
b <- 1
eval(q6)
q7 <- mask(q6, list(b=1000))
eval(q7)
```

## Substitute

Okay, almost there, one last little thing.  This isn't necessary, but can help
clean things up a little: an equivalent to `substitute` that captures the
Calling Environment like `enquo` does:

```{r}
withbq_arg <- function(x) {
  env <- parent.frame()
  caller <- sys.frame(sys.parent(2))
  cmd <- eval(bquote(.(substitute)(.(substitute(x)))), env)
  cmd <- eval(bquote(.(bquote)(.(cmd))), caller)
  bquote(with(.(caller), .(cmd)))
}
```

# Endgame

Now we can go back to our `mean_with_*` functions:
<!--
Can this ever fail do to the `eval` interim environment issue?  Probably not
because it doesn't make sense to evaluate `withbq_arg` anywhere other than in an
environment already on the context stack.
-->
```{r}
mean_with_bquo <- function(dat, cmd) {
  cmd <- bquote(mean(.(withbq_arg(cmd))))
  cmd <- mask(cmd, dat)
  eval(cmd)
}

f <- function(a) {
  list(
    bquote(mean(.(withbq_arg(a)))),
    evalq(bquote(mean(.(withbq_arg(a))))),
    withbq_arg(a)
  )
}
g <- function(a) {
  b <- quote(x)
  f(.(b) + 2)
}
z <- g(c / d)
z[[1]][[2]][[2]]
z[[2]][[2]][[2]]
z[[3]][[2]]

```

We use `bquote` to generate the `mean` call, but could also have used `withbq`.
It doesn't really matter since we're evaluating in the Function Evaluation
Environment thus the two are equivalent.  So does it work?

```{r}
l.per.cubic.i <- NA
local({
  mean <- function(...) 42
  l.per.cubic.i <- 2.54^3 / 1000
  list(
    base=mean_with_base(mtcars, disp * l.per.cubic.i),
    rlang=mean_with_rlang(mtcars, disp * l.per.cubic.i),
    withbq=mean_with_bquo(mtcars, disp * l.per.cubic.i)
  )
})
```

Yup!

```{r}
a <- 17
b <- 59
w <- local({
  b <- 1e6
  withq(a + b)
})
exp <- local({
  b <- 100
  x <- 3
  withbq(x + 1 + .(w))
})
exp
eval(exp)

w <- 1
f <- local({
  w <- 2
  function(x) {
    w <- 5
    withbq_arg(x)
  }
})
f(w)
eval(f(w))
```

# Names

```{r}
q_with_env
bq_with_env
bq_arg_with_env

quote_w
bquote_w
bquote_arg_w


sub_arg_w
bquote_subarg_w
bq_subarg_w

q_w
bq_w
bq_subarg_w
bq_arg_w

```



<!-- this needs to become a shortcode -->
<img
  id='front-img' src='/front-img/default.png'
  class='post-inset-image'
/>


# What does it for self eval formula

* Override `~` in the mask environment
* Need access to the actual formula somehow.  We can get the call with
  `sys.call`.  And if the environment is attached to the unevaluated quosure
  itself then it can be retrieved from `sys.call`, and it seems that's what
  !! as that's how it works does?

```{r eval=FALSE}

`~` <- function(...) {
  call <- sys.call()
  env <- parent.frame()
  is.quo <- function(x)
    is.call(x) && is.environment(attr(x, '.Environment')) &&
    inherits(x, 'bquosure')
  if(!is.quo(call)) {
    tilde <- get('~', mode='function', envir=env)
    eval(bquote(.(tilde))(...), env)
  } else {
    eval(substitute(list(...))[[3]], attr(x, '.Environment'))
  }
}

library(rlang)
`~` <- function(...) stop('boom')
~ 1 + 1
x <- quo(~1 + 1)
eval_tidy(x)
rm(`~`)
x <- quo(~1 + 1)
eval_tidy(x)



```

# Original Garbage

# References

* [TidyEval Bookdown][22]

# Conclusions

<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<p id='feedback-cont'></p>

# Appendix

## Acknowledgments

I'd like to thank Lionel Henry for all the work he's done developing and
implementing his ideas on meta-programming in R, and for being so gracious in
discussing it with me given that he knows I harbor somewhat adversarial views.
I've learned a lot from looking at his code and from getting his perspectives on
potential alternative implementations of some of the `rlang` concepts.



## Code


Without substitute equivalent
```{r}
mean_with_bquo <- function(dat, cmd) {
  env <- parent.frame()
  cmd <- withbq(.(substitute(cmd)), env)
  cmd <- bquote(mean(.(cmd)))
  cmd <- mask(cmd, dat)
  eval(cmd)
}
# stress testing everything working properly
mean_with_bquo <- function(dat, cmd) {
  cmd <- mask(bquote(mean(.(withbq(.(substitute(cmd)), env)))), dat)
  eval(cmd)
}
```

```{r echo=FALSE, eval=FALSE}
withbq <- function(x) {
  caller <- parent.frame()
  exp <- substitute(x)            # a + .(a)         # user cmd
  exp <- bquote(.(bquote)(.(exp)))# bquote(a + .(a)) # wrap in bquote
  exp <- eval(exp, caller)        # a + 666          # eval in call env
  bquote(with(.(caller), .(exp)))
}
```

## Session Info

[1]: /2020/05/05/on-nse/
[2]: /2020/05/05/on-nse/#call-assembly
[3]: /2020/05/05/on-nse/#nse-in-functions
[4]: https://en.wikipedia.org/wiki/Quasi-quotation
[5]: https://en.wikipedia.org/wiki/Willard_Van_Orman_Quine
[6]: https://www.cs.unm.edu/~williams/cs491/quasiquote.ps
[22]: https://tidyeval.tidyverse.org/
[23]: https://github.com/r-lib/rlang/issues/924
[24]: https://www.r-project.org/dsc/2017/slides/tidyeval-hygienic-fexprs.pdf
[25]: https://schd.ws/hosted_files/user2017/43/tidyeval-user.pdf
[26]: https://blog.obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/

[^alternatives]: Another solution would be to compute the user
  command by group first, and subsequently `lapply` `mean` over the resulting
  values.  This is a better solution, except for that it side-steps the problem
  we are trying to highlight, perhaps results in higher peak memory usage as we
  must hold the user command evaluated for every group in memory, and it only
  works if the user command contains no aggregating functions.
[^shortcomings]: Likely the most problematic one is that if the user command
  causes an error, the error backtrace will display the function in full rather
  than the name of the function, which may be confusing.
[^resentment]: Oh no, I bear no resentment whatsoever to philosopher's whose
  works were required readings for me back in the day.
[^alternate-names]: This is a set of names I came up with in five minutes for
  the primary `rlang` names:
  * bquo <- expr
  * quo_arg <- enexpr
  * quo_dots <- enexprs
  * bquosure <- quo
  * quosure_arg <- enquo
  * quosure_dots <- enquos (alt: bquosure_args)
[^uncomfortable]: I don't think it is documented that the attributes of call
  that was evaluated will be put along with the call onto the call stack.
  Maybe there is some implicit guarantee that this will always be the case, or
  perhaps different interpretation 
  it's one of those things
  I wouldn't have been
  surprised if only the actual call was put on the stack.
[^odd-bquote]: We embed the actual `bquote` function rather than just the name
  to avoid potential conflicts with re-mappings of the `bquote` name in the
  Calling Environment.
[^subly-affected]: [Until recently ][23] it was not possible to reference a
  custom, non-quosure tilde defined as part of a quosure's Environment Chain as
  the `eval_tidy` special tilde would interfere.  While that works now (at least
  in the dev versions), commands such as `get("~")` will still retrieve the
  `rlang` tilde.
[^namespace-kinda]: Normally the package namespace environment would also
  contain the function(s), not just act as the Function Environment.  This
  allows package functions to find each other, but that is not necessary here.
  Additionally, there would be import environments exposing the package imports
  to our functions, but here we just set a namespace as the enclosure and don't
  worry about the details.  Finally, there is no package environment to add to
  the search path.  We just leave the function floating around in the global
  environment.  Think of it as an eviscerated package, entrails on display yet
  somehow partially functioning.  For more details on package environments see
  Saruj Gupta's excellent ["How R Searches and Finds Stuff"][26].
[^mostly-reasonable]: Except maybe for the argument supporting `!!`, which from
  what I understand is based on the idea that it is inappropriate to represent
  partial evaluation with a function, which while I can concede being something
  worth contemplating in theory, cannot possibly justify the blown brains,
  heartbreak, tears, precedence disarray, and parser disrespect in reality,
  especially given that unary operators are ... functions.
