---
title: Faster Group Stats in Base R
author: ~
date: '2019-03-03'
slug: faster-group-stats-in-base-r
categories: []
tags: []
image: /front-img/default.png
imagerect: ~
imagemrgvt: 0%
imagemrghz: 0%
draft: true
weight: 1
contenttype: article
description: Front page summary
---

```{r echo=FALSE}
options(digits=3)
knitr::opts_chunk$set(comment = "", fig.align='center', error=TRUE)
```

# blah blah

<!-- this needs to become a shortcode -->
<img
  id='front-img' src='/front-img/default.png'
  class='post-inset-image'
/>

# Baseline

```{r eval=FALSE}
RNGversion("3.5.2"); set.seed(42)
n     <- 1e7
n.grp <- 1e6
grp   <- sample(n.grp, n, replace=TRUE)
x     <- runif(n)
y     <- runif(n)

system.time(x.ref <- c(tapply(x, grp, sum)))
```
```
   user  system elapsed
  8.539   0.321   9.030
```
```{r}
library(data.table)
DT <- data.table(grp, x)
setDTthreads(1)
system.time(x.dt <- DT[, sum(x), keyby=grp][[2]])
```
```
   user  system elapsed
  1.056   0.061   1.126
```

# Simple But Limited

Our first solution uses `base::rowsum`.  As is clearly indicated by the lack of
capitalization and pluralization, `base::rowsum` is completely different from
`base::rowSums`.  Further, anyone who has read the "Semantics of Capitalization,
Punctuation, and Pluralization in R Function Names" memo can infer that the
former sums rows within groups, and the latter sums columns within rows.

You did get the memo, right?  Good.

Even though the function names are completely self explanatory, we will
illustrate for completeness:

```{r}
mx <- matrix(1:8, 4, byrow=TRUE) * 10 ^ (0:3)
mx
```
```{r}
rowsum(mx, group=rep(c('odd', 'even'), 2))
```

`rowsum` preserved the two columns, but collapsed the rows by the `group` value.

```{r}
rowSums(mx)
```

`rowSums` collapsed the columns but preserved the rows.  You can think of the
resulting vector as a 4 x 1 "column".

I have known about `rowSums` for a long time, and I only more recently
discovered `rowsum`.  It probably says more about me than I care to admit, but
when I first realized what `rowsum` _actually_ does I was about as excited
as a taxidermist might be when they first realize the just delivered cadaver is
not a dead white cat, but rather an albino possum.

How can a base R function possibly compete for excitement with a dead possum?
Well, there are many base R functions that compute on arbitrary groups, and many
base R functions that work directly in compiled code, but as far as I
know base R functions that compute on arbitrary groups in compiled code are few
and far between[^knowledge-caveat].  And this is very useful:

```{r eval=FALSE}
system.time(x.rs <- rowsum(x, grp))
```
```
   user  system elapsed
  2.505   0.096   2.626
```
```{r eval=FALSE}
all.equal(c(x.ref), c(x.rs), check.attributes=FALSE)
```
```
[1] TRUE
```

Almost four times faster 

I've attempted to measure the relative popularity of the
two functions, but try doing that in a search engine...  Thankfully years of
using "R" as a search term have inured me to this type of disappointment.  So I
don't if I'm just the loser that didn't get the memo or if `rowsum` is generally
less known.



if others typically run into `rowsum` far enough into their R learning
curve to be excited by what it is.


So I'm going on a limb based purely on anecdotal evidence that `rowSums` is far
more well known than `rowsum`.



I mean, c'mon, it's bad enough
that we have to search for "R", and now I'm trying to get differential hits for
"rowsum" vs "rowSums".

Jkk
Jkk
When I first
Before I proceed I want to point out how remarkable `rowsum` is


```{r eval=FALSE}
system.time({
  o <- order(grp)
  x.grp.2 <- rowsum(x[o], grp[o])
})
```
```
   user  system elapsed
  1.408   0.113   1.556
```
Slope:
```{r}
system.time({
o <- order(grp)
go <- grp[o]
xo <- x[o]
xs <- rowsum(xo, go)
xn <- rowsum(rep(1L, length(go)), go)
xi <- rep(seq_along(xs), xn)
xu <- (xs/xn)[xi]

yo <- y[o]
ys <- rowsum(yo, go)
yu <- (ys/xn)[xi]
x_ux <- xo - xu
y_uy <- yo - yu

rowsum(x_ux * y_uy, go) / rowsum(x_ux ^ 2, go)
})
```
```
   user  system elapsed
  4.655   0.772   5.516
```


```{r eval=FALSE}
# Note: adapted to handle na.rm as per winvector, don't necessarily
# handle corner cases correctly (0, 1 length vectors, others?)

# Note: this stuff is only fast because order(, method="radix") is fast
# Doesn't handle Infinite values

sum_g2 <- function(x, grp, na.rm=FALSE) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  grp.rle.c <- cumsum(grp.rle[['lengths']])
  x.ord <- x[ord]
  has.na <- anyNA(x)

  if(has.na) {
    na.x <- is.na(x)
    x.ord[na.x] <- 0
  } else na.x <- logical()

  x.grp.c <- cumsum(x.ord)[grp.rle.c]
  x.grp.c[-1L] <- x.grp.c[-1L] - x.grp.c[-length(x.grp.c)]

  if(!na.rm && has.na)
    x.grp.c[match(grp.ord[na.x], grp.rle[['values']])] <- NA

  structure(x.grp.c, groups=grp.rle[['values']], n=grp.rle[['lengths']])
}
system.time(sum_g2(x, grp))
```
```
   user  system elapsed
  1.186   0.374   1.634
```
Try slope:
```{r eval=FALSE}

sum_grp1_int <- function(x, last.in.group) {
  x.g <- cumsum(x)[last.in.group]
  x.g[-1L] <- x.g[-1L] - x.g[-length(x.g)]
  x.g
}
sum_grp1 <- function(x, last.in.group, precise=FALSE){
  x.grp <- sum_grp1_int(x, last.in.group)
  if(precise) {
    x[last.in.group] <- x[last.in.group] - x.grp
    x.grp + sum_grp1_int(x, last.in.group)
  } else x.grp
}
slope1 <- function(x, y, grp, precise=FALSE) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  grp.rle.c <- cumsum(grp.rle[['lengths']])
  x.ord <- x[ord]
  y.ord <- y[ord]

  x.grp.c <- sum_grp1(x.ord, grp.rle.c, precise=precise)
  y.grp.c <- sum_grp1(y.ord, grp.rle.c, precise=precise)

  ux <- x.grp.c / grp.rle[['lengths']]
  uy <- y.grp.c / grp.rle[['lengths']]

  xi <- rep(seq_along(ux), grp.rle[['lengths']])
  x_ux <- x.ord - ux[xi]
  y_uy <- y.ord - uy[xi]

  x_ux.y_uy <- sum_grp1(x_ux * y_uy, grp.rle.c, precise=precise)
  x_ux2 <- sum_grp1(x_ux ^ 2, grp.rle.c, precise=precise)
  x_ux.y_uy / x_ux2
}
system.time(slope1(x, y, grp, precise=FALSE))
```
```
   user  system elapsed
  2.049   0.805   2.871
```
Precision is garbage though:
```
> all.equal(res.slope.dt1[[2]], res4, tol=1e-2)
[1] TRUE
> all.equal(res.slope.dt1[[2]], res4, tol=1e-3)
[1] FALSE
```
But we can make it precise
```{r eval=FALSE}
system.time(slope1(x, y, grp, precise=TRUE))
```
```
   user  system elapsed
  2.481   1.087   3.754
  # second faster timing was from a fresh session, repeated several times
   user  system elapsed
  2.399   0.933   3.348
```

```{r eval=FALSE}
sum_g3 <- function(x, grp, na.rm=TRUE) {
  ord <- order(grp)
  id.ord <- id[ord]
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  max.grp <- max(grp.rle[['lengths']])

  # this NA handling doesn't work b/c for na.rm=FALSE you still get NAs

  res <- matrix(NA_real_, ncol=length(grp.rle[['lengths']]), nrow=max.grp)

  # each group that isn't as long as the longest group needs padding

  rle.len <- grp.rle[['lengths']]
  grp.pad <- max.grp - rle.len
  id.raw <- rep(1L, length(x))
  id.raw[(cumsum(rle.len) + 1L)[-length(rle.len)]] <-
    grp.pad[-length(rle.len)] + 1L
  id <- cumsum(id.raw)

  res[id] <- x[ord]
  structure(colSums(res, na.rm=na.rm), groups=grp.rle[['values']])
}
system.time(sum_g3(x, grp))
```
```
   user  system elapsed
  1.186   0.374   1.634
```
```{r eval=FALSE}
# lens: how long each group is
# maxlen: longest group
sum_grp2 <- function(x, lens, maxlen, mode='sum') {

  res <- matrix(NA_real_, ncol=length(lens), nrow=maxlen)

  # Generate indices that will map to the correct spots in `res` from `x`,
  # which means add whatever padding we need to the index value for the next
  # column

  len_1 <- lens[-length(lens)]
  grp.pad <- (maxlen + 1L) - len_1
  id.raw <- rep(1L, length(x))
  len_1[1L] <- len_1[1L] + 1L
  id.raw[cumsum(len_1)] <- grp.pad
  id <- cumsum(id.raw)

  # Inject the x values according to these indices that should place each gropu
  # in a column

  res[id] <- x

  if(identical(mode, 'sum')) colSums(res, na.rm=TRUE)
  else if(identical(mode, 'mean')) colMeans(res, na.rm=TRUE)
  else stop("Invalid mode")
}
slope2 <- function(x, y, grp) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  grp.len <- grp.rle[['lengths']]
  max.grp <- max(grp.len)

  xo <- x[ord]
  xi <- rep(seq_along(grp.len), grp.len)
  xu <- sum_grp2(xo, grp.len, max.grp, 'mean')
  x_ux <- xo - xu[xi]

  yo <- y[ord]
  yu <- sum_grp2(yo, grp.len, max.grp, 'mean')
  y_uy <- yo - yu[xi]

  x_ux.y_uy <- sum_grp2(x_ux * y_uy, grp.len, max.grp, 'sum')
  x_ux2 <- sum_grp2(x_ux ^ 2, grp.len, max.grp, 'sum')

  x_ux.y_uy / x_ux2
}
slope2a_int <- function(xo, yo, lens) {
  max.grp <- lens[1]

  xi <- rep(seq_along(lens), lens)
  xu <- sum_grp2(xo, lens, max.grp, 'mean')
  x_ux <- xo - xu[xi]

  yu <- sum_grp2(yo, lens, max.grp, 'mean')
  y_uy <- yo - yu[xi]

  x_ux.y_uy <- sum_grp2(x_ux * y_uy, lens, max.grp, 'sum')
  x_ux2 <- sum_grp2(x_ux ^ 2, lens, max.grp, 'sum')

  x_ux.y_uy / x_ux2
}
slope2a <- function(x, y, grp, splits=5) {
  ord <- order(grp)
  grp.ord <- grp[ord]
  grp.rle <- rle(grp.ord)
  grp.len <- grp.rle[['lengths']]

  ord2 <- order(rep(grp.len, grp.len), decreasing=TRUE)
  ordg <- order(grp.len, decreasing=TRUE)
  grp.len.o <- grp.len[ordg]
  len.max <- grp.len.o[1L]  # will break if no groups
  len.min <- grp.len.o[length(grp.len.o)]

  # order the inputs

  ord3 <- ord[ord2]
  xo <- x[ord3]
  yo <- y[ord3]
  go <- grp.ord[ord2]

  # simple initial cut, just cut into equal splits

  cuts <- as.integer(
    round(seq(1L, length(grp.len) + 1L, length.out=splits + 1L))
  )
  grp.len.o.c <- cumsum(c(1L, grp.len.o))
  res <- vector("list", splits)

  for(i in seq_len(splits)){
    # Figure out that starting and ending elements for each group

    start.g <- cuts[i]
    end.g <- cuts[i + 1L]

    start <- grp.len.o.c[start.g]
    end <- grp.len.o.c[end.g] - 1L

    idx.g <- start.g:(end.g - 1L)
    idx <- start:end

    res[[i]] <- slope2a_int(xo[idx], yo[idx], grp.len.o[idx.g])
  }
  # Reorder back in ascending group order instead of group size order

  res.fin <- numeric(length(grp.len))
  res.fin[ordg] <- unlist(res)
  res.fin
}
system.time(slope2(x, y, grp))
RNGversion("3.5.2"); set.seed(42)
x2 <- runif(100)
y2 <- runif(100)
g2 <- sample(1:10, 100, rep=T)
```
```
   user  system elapsed
  2.827   0.932   3.807
  # can't reproduce the earlier timings...
   user  system elapsed
  3.185   1.285   4.783
  # now I can ...
```
```{r eval=FALSE}
system.time(slope2a(x, y, grp))
```
```
   user  system elapsed
  2.998   1.055   4.082
```
```{r eval=FALSE}
dummy <- function(sizes) {
  res <- vector("list", length(sizes))
  for(i in seq_along(sizes)) {
    mx <- matrix(numeric(), nrow=sizes[i], ncol=as.integer(1e6 / length(sizes)))
    res[[i]] <- colSums(mx, na.rm=TRUE)
  }
}
system.time(dummy(c(28, 21, 14, 7, 1)))
```

```{r eval=FALSE}

DT <- copy(DT.raw)
system.time(res.ref <- DT[, sum(x), keyby=grp][['V1']])
#   user  system elapsed
#  1.071   0.134   1.216
system.time(res <- sum_g2(x, grp))
#   user  system elapsed
#  1.286   0.309   1.692
all.equal(res, res.ref, check.attributes=FALSE) # TRUE

system.time(res2 <- sum_g2(x, grp))
system.time(res3 <- sum_g3(x, grp))
system.time(res4 <- rowsum(x, grp))

sum_winvector <- function(DF) {
  odata <- DF[order(DF$grp),,drop=FALSE]
  first_indices <- mark_first_in_each_group(odata, "grp")
  sum_g(odata[['x']], first_indices)
}
```
```
  user  system elapsed
 1.810   0.740   2.651
```
Note on vector size[^vec-size].


# Conclusions

<!-- this needs to become a shortcode -->
<!-- this is populated by JS in feedback.html partial -->
<div id='feedback-cont'></div>

# Appendix

[^knowledge-caveat]: Given how long it's taken me to find out about `rowsum` it
is fair to question whether I would know whether there are many other functions
of this kind out there or not.
[^vec-size]: Numeric vectors require 8 bytes per element plus some overhead for
the object meta data.
[^love-r-but]: I love R, but the maddness around [text decoration
conventions][1] is something that I could do without.  Sorry for the rant, but I
was particularly triggered by this example.

[1]: https://twitter.com/BrodieGaslam/status/976616435836510210
