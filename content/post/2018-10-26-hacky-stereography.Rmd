---
title: Hacky Stereography
author: ~
date: '2018-10-26'
draft: true
slug: hacky-stereography
categories: []
tags: []
---
```{r echo=FALSE}
knitr::opts_chunk$set(
  comment = ""
)
options(digits=3)
```

# Cool, but Not Eye Popping

As we saw in our previous [blog post](/2018/10/23/do-not-shade-r/), you can do
some pretty cool things with `rayshader`:

It is so beautiful it looks _almost_ 3D.  So why not actually make it 3D?  We
have the elevation data after all.  Much of what we are going to do here can be
done with `rgl`, but what's the fun in that?  Besides, there are few things as
fun as procrastinating by learning about a fundamental component of computer
graphics.  Okay, maybe I don't get out much.

So come along for a ride through 3D projections, perspective adjustments,
rasterization, and image processing, all in base R.

# Step 0: Volcano!

Sure, you've seen volcano a million times:

```{r fig.width=5}
scale <- function(x, range=1, center=0.5)
  ((x - min(x, na.rm=TRUE)) / diff(range(x, na.rm=TRUE))) * range +
   (1 - range) * center
flip <- function(x) t(x)[rev(seq_len(ncol(x))),]

# plot(as.raster(flip(scale(volcano))))

par(mai=numeric(4L), xaxt='n', yaxt='n', xaxs='i', yaxs='i')
plot.new()
plot.window(c(0,1), c(0,1), asp=ncol(volcano)/nrow(volcano))
points(
  x=scale(row(volcano)), y=scale(col(volcano)),
  col=gray(scale(volcano)), pch=15
)
```

Let's add some shading:

```{r fig.width=5}
library(shadow)
sh <- ray_shade2(volcano, seq(-90, 90, length=25), sunangle=180)
par(mai=numeric(4L), xaxt='n', yaxt='n', xaxs='i', yaxs='i')
plot.new()
points(
  x=scale(row(volcano)), y=scale(col(volcano)),
  col=gray(sh), pch=15
)
```

# Step 1: 3D Projection

While volcano looks pretty cool from above, we want to provide a more
interesting view.  To do this we can use [3D rotation matrices][1].  `shadow`
implements the `rot_*` functions, which are thin wrappers that generate the
rotation matrices described in the wikipedia article:

```{r}
rot_z(90)
```

By our convention the Z-axis is always pointed directly at the user, even after
rotations are applied.  In other words, it is the model that rotates, not the
viewer[^1].

In order to use the rotation matrix we need our data in long format.  This can
be done easily by taking advantage of the `row` and `col` functions that return
respectively the row and column indices of each element in the vector underlying
the matrix:

```{r}
mx.example <- matrix((0:3)*10, nrow=2, ncol=2)
row(mx.example)
col(mx.example)
cbind(c(row(mx.example)), c(col(mx.example)), c(mx.example))
```

So now we can make a long version of `volcano`:

```{r}
volc.l <- rbind(x=c(row(volcano)), y=c(col(volcano)), z=c(volcano))
str(volc.l)
str(volcano)
```

Which we can rotate with our rotation matrices:

```{r}
rot <- rot_x(-20) %*% rot_z(65)
volc.lr <- rot %*% volc.l
```

From this point forward we will be using list data structures instead of
matrices as we have found them [to be more efficient][2] for the problem we're
dealing with.

```{r, echo=FALSE}
asp <- diff(range(volc.lr[2,])) / diff(range(volc.lr[1,]))
plot.window(0:1, 0:1, asp=asp)
```
<a name='volcano-list-long'></a>
```{r}
## construct list data structure, adding texture/shadow info
vl <- lapply(seq_len(nrow(volc.lr)), function(x) volc.lr[x,])
vl <- c(vl, list(sh))              # add texture info
names(vl) <- c('x', 'y', 'z', 't') # 't' for texture

## Plot!, but order by Z value first
zord <- order(vl[[3]])
vlo <- lapply(c(1:2,4), function(x) scale(vl[[x]][zord]))
par(mai=numeric(4))
plot.new()
points(x=vlo[[1]], y=vlo[[2]], col=gray(vlo[[3]]), pch=15, cex=0.5)
```

The good news is now we have an awesome looking 3D rendition of our volcano...
in the process of disintegration from a particularly unpleasant eruption.

# Meshes

Okay, so we can't just use our elevation data as point coordinates.  One
possibility is to turn our point "cloud" into a mesh.  Well, turning an
arbitrary point cloud into a mesh is one of those problems that seems very easy
but in reality is anything but.  Worse, the typical implementations involve some
kind of sequential process that is repeated many times until the mesh is
complete.  These types of algorithms cannot be implemented efficiently in R,
though there are R packages that implement them in compiled code.

Fortunately for us and our base-R only challenge, our point cloud is not
arbitrary.  The source data contains the information required to build the mesh:
the original x-y grid.  We can generate a tile mesh by sampling our data four
times, once for each of the four vertices for each tile.  This is what it looks
like with an illustrative 4 x 4 grid:

```{r echo=FALSE, fig.width=5.5, fig.height=1.5}
p.seq <- seq(.05, .95, length.out=4)
points <- expand.grid(x=p.seq, y=p.seq)
len <- length(p.seq)
vert.box <- data.frame(
  x=c(.025, p.seq[3] + .025, p.seq[3] + .025, .025),
  y=c(-.025 + p.seq[2], -.025 + p.seq[2], .025 + p.seq[4], .025 + p.seq[4])
)
seq.diff <- diff(p.seq[1:2])
# dev.new(width=5, height=1.5)
old.par <- par(mfrow=c(1,4), mar=c(.5, .25, 2, .25))
x.off <- c(0, 1, 1, 0)
y.off <- c(1, 1, 0, 0)
for(i in seq_along(p.seq)) {
  plot.new()
  plot.window(0:1, 0:1, asp=1)
  title(sprintf('Vertex %d', i))
  polygon(c(0, 1, 1, 0), c(0, 0, 1, 1), col='#EEEEEE', border=NA)
  points(points, pch=15, cex=0.5)
  polygon(
    x=vert.box[['x']] + seq.diff * x.off[i],
    y=vert.box[['y']] - seq.diff * y.off[i]
  )
}
par(old.par)
```

We alternate dropping the first/last row/column.  Because our rotated volcano
data is already in long format this requires a little extra work:

```{r}
nr <- dim(volcano)[1]
nc <- dim(volcano)[2]
idx.raw <- matrix(seq_along(volcano), nr, nc)
idx.tile <- list(
  idx.raw[-nr, -nc, drop=TRUE],
  idx.raw[-nr,  -1, drop=TRUE],
  idx.raw[ -1,  -1, drop=TRUE],
  idx.raw[ -1, -nc, drop=TRUE]
)
```

For each of our vectors from our rotated volcano, we will use `idx.tile` to pull
out the vertex data for the tiles.  This does unfortunately mean we have several
duplicative copies of the same data.

```{r}
mesh.tile <- matrix(
  Map(
    function(x, y) vl[[y]][idx.tile[[x]]],
    rep(seq_along(idx.tile), length(vl)),
    rep(seq_along(vl), each=length(idx.tile))
  ),
  nrow=length(idx.tile),
  ncol=length(vl),
  dimnames=list(sprintf('v%d', seq_along(idx.tile)), names(vl))
)
```

Tada! A mesh:

```{r}
par(mai=numeric(4))
zord4 <- order(Reduce('+', mesh.tile[,'z']))
x4 <- do.call(rbind, c(mesh.tile[,'x'], list(NA)))[,zord4]
y4 <- do.call(rbind, c(mesh.tile[,'y'], list(NA)))[,zord4]
plot.new()
polygon(scale(x4), scale(y4), col='#EEEEEE')
```

Okay, great you say, but we could have done all of this with `persp`, why
bother?  The reality is we're not done.  Consider what we get with `persp`:

```{r}
par(mai=numeric(4))
# persp(
#   volcano, theta=-65, phi=70, r=1e6, col=gray(sh[-1,-1]),
#   border=NA, box=FALSE, axes=FALSE
# )
persp(
  x=seq_len(nrow(volcano)), y=seq_len(ncol(volcano)), z=volcano,
  theta=-65, phi=70, col=gray(sh[-1,-1]), r=1e6,
  border=NA, box=FALSE, axes=FALSE, scale=FALSE
)
```

This isn't great because of how blocky it is, and also because there is no good
way to get rid of the borders.  Additionally it is a bit slow.

But a tile mesh is not ideal.  Among other things, there is no guarantee the
tiles are flat.  Triangles on the other hand are guaranteed to be flat, and
additionally benefit from simple shading algorithms.  So we will turn our tiles
into triangles as we do here by turning the black tile into the blue and green
triangles:

```{r echo=FALSE}
par(mai=numeric(4))
plot.new()
polygon(scale(c(0, 1, 1, 0), .9), scale(c(0, 0, 1, 1), .9), col='#EEEEEE')
text(
  scale(c(0, 1, 1, 0), .95), scale(c(0, 0, 1, 1), .95),
  labels=sprintf('v%d', 1:4)
)
polygon(
  scale(c(0, 1, 1), .8) + .0125, scale(c(0, 0, 1), .8) - .0125,
  border='#0000FF', col='#CCCCFF'
)
text(
  scale(c(0, 1, 1), .7) + .03, scale(c(0, 0, 1), .7) - .03,
  labels=sprintf('v%d', 1:3), col='#0000AA'
)
polygon(
  scale(c(1, 0, 0), .8) - .0125, scale(c(1, 1, 0), .8) + .0125,
  border='#00FF00', col='#CCFFCC'
)
text(
  scale(c(1, 0, 0), .7) - .03, scale(c(1, 1, 0), .7) + .03,
  labels=sprintf('v%d', c(3,4,1)), col='#00AA00'
)
```

Our data is nicely structured that the translation from tile to triangle mesh is
trivial:

```{r}
vertex.blue <- 1:3
vertex.green <- c(3,4,1)
mesh.tri <- Map('c', mesh.tile[vertex.blue,], mesh.tile[vertex.green,])
dim(mesh.tri) <- c(3, 4)
dimnames(mesh.tri) <- list(head(rownames(mesh.tile), -1), colnames(mesh.tile))
mesh.tri
```

And we can plot this.

```{r}
zord3 <- order(Reduce('+', mesh.tri[,'z']))
x3 <- do.call(rbind, c(mesh.tri[,'x'], list(NA)))[,zord3]
y3 <- do.call(rbind, c(mesh.tri[,'y'], list(NA)))[,zord3]
par(mai=numeric(4))
plot.new()
polygon(scale(x3), scale(y3),
  col=rep(c('#CCCCFF','#CCFFCC'), each=ncol(x3)/2)[zord3]
)
```

Let's shade each facet with the mean of the vertex shadows:

```{r}
par(mai=numeric(4))
texture3 <- gray(Reduce('+', mesh.tri[,'t']) / 3)[zord3]
plot.new()
polygon(scale(x3), scale(y3), col=texture3, border=texture3)
```

Looks better than `persp`, but still the triangle faces irk me.  Also, I'm
curious about how `polygon` takes the `polygon` data and renders it on the
devices (or how the device does it).  Finally, this doesn't scale well to large
polygon counts <span color='red'>ADD EXAMPLE?</span>.

```{r eval=FALSE}
width <- height <- 600
# par3d(windowRect=c(0,0,width*2,height))
par3d(windowRect=c(0,0,width,height))
clear3d()
polygon3d(x=c(0, 1, 2, 1, 0), y=c(0, 2, 0, .2, 0), z=numeric(5))
view3d(0,0,fov=60)
```

# Perspective

Everything we've done so far has been assuming there is no perspective effect,
that is, that the perceived size of objects is independent of the distance from
the observer.  This is true if objects are infinitely far away.

So far we have define our observer as being on a line parallel to the Z axis and
passing through the midpoint of the X and Y extents of the projected object.
Thus we have always been look at `volcano` straight down the Z axis.  For
expository purposes we are about to, for the first time, rotate "Observer 0"
(you) 90 degrees about the Y axis.

In the following diagram we have rotated "Observer 0" (you) so that it is now
looking at `volcano` down the X axis.  The Z axis now runs from left to right.
Observers 1, 2, and 3 are all still looking at `volcano` down the Z axis.

```{r echo=FALSE, fig.width=7, fig.height=2.33}
rot2 <- rot_x(-20) %*% rot_z(65) %*% rot_x(-90)
volc.l2 <- rbind(x=c(row(volcano)), y=c(col(volcano)), z=c(volcano))
volc.lr2 <- rot2 %*% volc.l

vl2 <- lapply(seq_len(nrow(volc.lr2)), function(x) volc.lr2[x,])
vl2 <- c(vl2, list(sh))              # add texture info
names(vl2) <- c('x', 'y', 'z', 't') # 't' for texture

mesh.tri2 <- shadow::mesh_tri(vl2, dim(volcano))
zord32 <- order(Reduce('+', mesh.tri2[,'z']))
x32 <- do.call(rbind, c(mesh.tri2[,'x'], list(NA)))[,zord32]
y32 <- do.call(rbind, c(mesh.tri2[,'y'], list(NA)))[,zord32]
texture32 <- gray((Reduce('+', mesh.tri2[,'t'])/4))[zord32]

yscale <- .8
ylow <- (1 - yscale) * .9
ymid <- .25 + yscale/2
yarrow <- scale(c(0, .5, 1), yscale * .5, 0) + ylow
yarmax <- max(yarrow)

par(mai=numeric(4))
plot.new()
polygon(scale(x32, 1/3, 1), scale(y32, yscale, 1),
  col=texture32, border=texture32
)
arrows(
  x0=c(0,  1/3, 1/2, 2/3),
  x1=c(2/3,2/3, 2/3,   1),
  y0=c(yarrow, ylow),
  y1=c(yarrow, ylow),
  col=c(rep('blue', 3), '#00DD00'),
  code=3
)
lines(
  c(0, 0, NA, 1/3, 1/3, NA, 1/2, 1/2, NA, 2/3, 2/3, NA, 1, 1, NA),
  c(ylow,                        ymid, NA,
    ylow + (yarmax - ylow) * .5, ymid, NA,
    yarmax,                      ymid, NA,
    ylow,                         .75, NA,
    ylow,                         .83, NA),
  lty='dashed',
  col='gray'
)
points(c(0, 1/3, 1/2), y=rep(ymid, 3), col='blue', pch=16)
text(
  x=c(2/3 * .5, 1/3 + 1/6, 1/2 + 1/12, 2/3 + 1/6),
  y=c(yarrow - ylow/2, ylow/2),
  col=c(rep('blue', 3), '#00DD00'),
  label=c('D = ZD * 2', 'D = ZD', 'D = ZD / 2', 'ZD = Z Depth'),
  cex=0.8
)
text(
  x=c(0, 1/3, 1/2), y=rep(ymid, 3), col='blue', pos=3,
  label=sprintf('Obs %d', 1:3)
)
```

For convenience we define the quantity `ZD` as the total depth of our object
along the Z axis.  Then, we can define the distance of our observers from the
nearest point along the Z axis with the measure `D` as multiples of `ZD`.

Here is our volcano re-rendered from the perspective of each of observers 1-3
pictured above:

```{r echo=FALSE, fig.width=7, fig.height=3}
par(mfrow=c(1,3), mar=c(.5, .25, 2, .25))
D.vals <- c(2,1,.5)
for(i in seq_along(D.vals)) {
  vlp <- shadow::perspective(vl, D.vals[[i]])
  vlpm <- shadow::mesh_tri(vlp, dim=dim(volcano))
  xi <- do.call(rbind, c(vlpm[,'x'], list(NA)))[,zord3]
  yi <- do.call(rbind, c(vlpm[,'y'], list(NA)))[,zord3]
  # zord <- order(Reduce('+', vlpm[,'z']))
  # texture <- Reduce('+', vlpm[,'t'])/3

  plot.new()
  plot.window(c(0,1), c(0,1), asp=diff(range(vlp['x']))/diff(range(vlp['y'])))
  title(sprintf('D = %.01f', D.vals[i]))
  polygon(scale(xi), scale(yi), col=texture3, border=texture3)
}
```

The actual perspective computation is best applied to the original point cloud,
so we go back to the `vl` variable, which is `volcano` in
[long list format](#volcano-list-long), and apply the perspective transformation
for observer 3:

```{r}
str(vl)                   # `volcano` in long list format
```{r eval=FALSE}
D <- 0.5                  # Observer 3 is half Z-Depth from volcano
z.rng <- range(vl[['z']])
ZD <- diff(z.rng)

## Normalize XY coordinates so observer is centered in midpoint of x-y extent
## and at Z=0
vlp <- vl
vlp[c('x','y')] <- lapply(vl[c('x','y')], function(x) x - sum(range(x)) / 2)
vlp[['z']] <- vlp[['z']] - (z.rng[2] + D * ZD)

## Apply perspective transformation
z.factor <- -1 / vlp[['z']]
vlp[c('x','y')] <- lapply(vlp[c('x','y')], '*', z.factor)
```
```{r echo=FALSE, eval=FALSE}
## just to confirm above works
vlp <- sapply(vlp, '[', order(vlp[['z']]), simplify=FALSE)
plot.new()
points(
  x=scale(vlp[['x']]), y=scale(vlp[['y']]), col=gray(vlp[['t']]), pch=15, cex=0.5
)
```

Now that we have the perspective-transformed cloud point, we can turn it back
into a triangle mesh.  This time we just use `shadow::mesh_tri`, which simply
carries out the calculations described in the [Mesh section](#meshes):

```{r}
mesh.tri <- mesh_tri(vlp, dim(volcano))
mesh.tri
zord <- order(Reduce('+', mesh.tri[,'z']))
x <- do.call(rbind, c(mesh.tri[,'x'], list(NA)))[,zord]
y <- do.call(rbind, c(mesh.tri[,'y'], list(NA)))[,zord]
texture <- gray((Reduce('+', mesh.tri[,'t'])/nrow(mesh.tri)))[zord]
par(mai=numeric(4))
plot.new()
plot.window(c(0,1), c(0,1), asp=diff(range(vlp[['x']]))/diff(range(vlp[['y']])))
box('figure')
polygon(scale(x), scale(y), col=texture, border=texture)
```

Are we there yet?  Nope, we're going to drag this baby kicking and screaming
all the way to its painful, bloody conclusion.

# Rasterization

## Overview

So far we have relied on base R plotting facilities, `polygon` mostly, to
actually transform our 3D object representation into an image.  There are two
problems with this:

1. `volcano` does not look very natural with all the triangular faces.
2. Speed is a problem with higher polygon counts.

We will resolve these issues by resorting to rasterization, whereby we compute
what each pixel of our final image should look like.  This requires determining
which points of our final output pixel grid belong to which triangles.  While
this is the type of thing a child could do easily, it is surprisingly difficult
to instruct a computer to do the same, particularly when we need to account for
the need to use internally vectorized base R code.

Conceptually, the process takes three steps:

```{r echo=FALSE, fig.width=7, fig.height=3}
par(mfrow=c(1, 4), mar=c(.5, .25, 2, .25))
x <- c(0, .8, .2, NA, .8, 1, .2, NA)
y <- c(0, .2, .8, NA, .2, 1, .8, NA)
plot.new()
title('Mesh Polygons to Rasterize')
polygon(x, y, col=c('#CCCCFF','#CCFFCC'), border=NA)
plot.new()
title('Step 1: Rectangular Bounding Box')
polygon(x, y, col=c('#CCCCFF','#CCFFCC'), border=NA)
polygon(
  c(0, .8, .8,  0, NA, .2, 1, 1, .2, NA),
  c(0,  0, .8, .8, NA, .2, .2, 1, 1, NA),
  border=c('#0000FF', '#00DD00'), col=NA
)
plot.new()
title('Step 2: Candidate Pixels')
len <- 13
pdat <- as.matrix(
  expand.grid(x=seq(0, .8, length.out=len), y=seq(0, .8, length.out=len))
)
polygon(x, y, col=c('#CCCCFF','#CCFFCC'), border=NA)
polygon(
  c(0, .8, .8,  0, NA, .2, 1, 1, .2, NA),
  c(0,  0, .8, .8, NA, .2, .2, 1, 1, NA),
  border=c('#0000FF', '#00DD00'), col=NA
)
points(pdat, pch=24, col='#0000FF')
points(pdat + .2, pch=25, col='#00DD00')

plot.new()
title('Step 3: Actual Pixels')

nr <- nrow(pdat)
mx1 <- matrix(c(lapply(x[1:3], rep, nr), lapply(y[1:3], rep, nr)), 3)
colnames(mx1) <- c('x', 'y')
mx1.oob <- Reduce('|', lapply(barycentric(as.data.frame(pdat), mx1), '<', 0))

mx2 <- matrix(c(lapply(x[5:7], rep, nr), lapply(y[5:7], rep, nr)), 3)
colnames(mx2) <- c('x', 'y')
mx2.oob <- Reduce('|', lapply(barycentric(as.data.frame(pdat+.2), mx2), '<', 0))

polygon(x, y, col=c('#CCCCFF','#CCFFCC'), border=NA)
points(pdat[!mx1.oob,], pch=24, bg='#0000FF', col=NA)
points(pdat[!mx2.oob,] + .2, pch=25, bg='#00DD00', col=NA)
```

## Step 1: Bounding Box

Let's first scale our data to be 600 pixels wide.  We go back to the
perspective-adjusted point cloud data to minimize the number of transformations
we need to make:

```{r}
x.width <- 600L
x.rng <- range(vlp[['x']])
y.rng <- range(vlp[['y']])
asp <- diff(x.rng) / diff(y.rng)
y.width <- as.integer(x.width * asp)
vlpt <- vlp
vlpt[['x']] <- scale(vlpt[['x']], x.width - 1L, 0)
vlpt[['y']] <- scale(vlpt[['y']], y.width - 1L, 0)
```

Regenerate the mesh, and for each mesh polygon compute the maximum x and y
integer pixel values they could contain:

```{r}
mesh <- mesh_tri(vlpt, dim(volcano))
mins <-
  apply(mesh[,c('x','y')], 2, function(x) list(ceiling(do.call(pmin, x))))
maxs <-
  apply(mesh[,c('x','y')], 2, function(x) list(floor(do.call(pmax, x))))
str(mins)  # `maxs` will have same structure
```

We use `list(...)` in the function to prevent `apply` from simplifying to
matrix.

## Step 2: Candidate Pixels

Compute how many the dimensions of the bounding x/y min/max in pixels:

```{r}
dims.x <- pmax(maxs[['x']][[1]] - mins[['x']][[1]] + 1, 0)
dims.y <- pmax(maxs[['y']][[1]] - mins[['y']][[1]] + 1, 0)
dims.xy <- dims.x * dims.y
```

Now the tricky part: we need to fill out the bounding boxes described by `mins`
and `maxs` with every permutation of x and y pixel coordinates.  The plan of
attack is to compute the pixel "offset" permutations within each bounding box,
and then add back the min x and y coordinates to get the actual pixel
coordinates.

This is the type of thing that one might normally do with `expand.grid`, but we
need to do this for each of the 10,320 polygons[^2] which becomes
computationally burdensome:

```{r eval=FALSE}
make_grids <- function() {
  lapply(seq_along(dims.x),
    # function(x, y) expand.grid(x=seq_len(x), y=seq_len(y)), dims.x, dims.y
    function(i) {
      x <- dims.x[[i]]
      y <- dims.y[[i]]
      list(
        rep(seq_len(x),y) + mins[['x']][[1]][i],
        rep(seq_len(y), each=x) + mins[['y']][[1]][i]
      )
    }
  )
}
stack_grids <- function(grids) {
  grid.dat <- make_grids()
  list(
    unlist(lapply(grids, '[', 'x')),
    unlist(lapply(grids, '[', 'y'))
  )
}
compute_bary <- function() {
  lapply(
    idx,
    function(i) {
      points <- grids[[i]]
      vertices <- lapply(mesh, '[', i)
      dim(vertices) <- dim(mesh)
      dimnames(vertices) <- dimnames(mesh)
      barycentric(points, vertices)
  } )
}
render_each <- function() {
  grids <- make_grids()
  bc <- compute_bary()
  idx <- seq_along(grids)
  inb <- lapply(bc, function(x) x[[1]] >= 0 & x[[2]] >= 0 & x[[3]] >= 0)
  p.inb <- lapply(idx, function(i) lapply(grids[[i]], '[', inb[[i]]))
  bc.inb <- lapply(idx, function(i) lapply(bc[[i]], '[', inb[[i]]))
  texture <- lapply(
    idx,
    function(i) Reduce('+', Map('*', lapply(mesh[, 't'], '[', i), bc.inb[[i]]))
  )
  zs <- unlist(lapply(idx, function(i) Reduce('+', lapply(mesh[, 'z'], '[', i))))
  zord <- order(zs)
  xs <- unlist(lapply(p.inb, '[[', 'x')[zord])
  ys <- unlist(lapply(p.inb, '[[', 'y')[zord])
  ts <- unlist(texture[zord])

  res <- matrix(numeric(), x.width, y.width)
  res[cbind(xs, ys)] <- ts
}
treeprof::treeprof(render_each())
plot(as.raster(res))

system.time(
  lapply(bc, function(x) x[[1]] >= 0 & x[[2]] >= 0 & x[[3]] >= 0)
)
```





```{r eval=FALSE}
library(shadow)
mx2 <- volcano
els <- seq(-90, 90, length=25)
sun <- 180
sh2 <- ray_shade2(mx2, els, sun)
sh2 <- sh2 * .9 + .1
rot <- rot_x(-20) %*% rot_z(65)

treeprof::treeprof(
proj <- project_elev(
  mx2, sh2, rot, parallax=0, dist=.5, resolution=c(600,600)
))

left <- proj[[1]]
empty.rows <- which(empty_rows(left))
empty.cols <- which(empty_cols(left))
left <- left[-empty.rows, -empty.cols, ]

left.r <- left[,,1]
left.r[left.r < 0] <- 0

## image(left.r)
plot(as.raster(left.r))
```

# Stereoscopy in R

After figuring out how to implement ray-shading with base R I was left wanting a
little more.  The shading is so effective at conveying the impression of depth,
but I r

## stereo angle

```{r rgl, eval=FALSE}
empty_rows <- function(arr) (rowSums(arr) == 3 * ncol(arr))
empty_cols <- function(arr) (rowSums(colSums(arr)) == 3 * nrow(arr))

angle <- 4

library(rgl)
rot.rgl <-
  rotationMatrix(-20/180*pi, 1, 0, 0) %*% rotationMatrix(65/180*pi, 0, 0, 1)

mfrow3d(1, 2)
width <- height <- 600
# par3d(windowRect=c(0,0,width*2,height))
par3d(windowRect=c(0,0,width,height))
# par3d(viewport=c(0,0,width,height))
# mx <- volcano[,rev(seq_len(ncol(volcano)))]
# sh2 <- sh[,rev(seq_len(ncol(sh)))]

persp3d(
  x=seq_len(nrow(volcano)), y=seq_len(ncol(volcano)),
  z=c(volcano), color=gray(sh), lit=FALSE, aspect="iso",
  box=FALSE, axes=FALSE, xlab="", ylab="", zlab=""
)
rgl.viewpoint(userMatrix=rot.rgl, fov=60)
view3d(0,0,fov=0)

# persp3d(seq_len(nrow(mx)), seq_len(ncol(mx)), c(mx),
#   color=rgb(c(sh2), c(sh2), c(sh2)), lit=FALSE,
#   xlab="X", ylab="Y", zlab="Z", box=FALSE, axes=TRUE
# )
# persp3d(mx,
#   color=rgb(c(sh2), c(sh2), c(sh2)), lit=FALSE,
#   xlab="X", ylab="Y", zlab="Z", box=FALSE, axes=TRUE
# )
view3d(0,0, )
rgl.viewpoint(userMatrix=rot, fov=0)

# next3d()
# persp3d(seq_len(nrow(mx)), seq_len(ncol(mx)), c(mx),
#   color=rgb(c(sh), c(sh), c(sh)), lit=FALSE,
#   xlab="X", ylab="Y", zlab="Z", box=FALSE, axes=TRUE
# )
# view3d(0,0)


image(sh2)


M <- identityMatrix()

play3d(
  par3dinterp(time = (0:2)*0.75, userMatrix=list(M,
                                     rotate3d(M, pi/2, 1, 0, 0),
                                     rotate3d(M, pi/2, 0, 1, 0) ) ) )

aspect3d(1, 1, 1)
rgl.viewpoint(userMatrix=t(XR) %*% t(ZRl), type='modelviewpoint', zoom=.7)
snapshot3d('persp-left.png')

clear3d()
persp_elev(mx, sh.s)
rgl.viewpoint(userMatrix=t(XR) %*% t(ZRr), type='modelviewpoint')
snapshot3d('persp-right.png')

# stitch images together

left <- png::readPNG('persp-left.png')
right <- png::readPNG('persp-right.png')
stopifnot(identical(dim(left), dim(right)))

# remove rows and columns that are blank in both images

empty.rows <- which(empty_rows(left) & empty_rows(right))
empty.cols <- which(empty_cols(left) & empty_cols(right))
left <- left[-empty.rows, -empty.cols, ]
right <- right[-empty.rows, -empty.cols, ]

# figure out how close we can get the left and right images before we
# start overlapping non-white pixels

no.overlap <- rowSums(left[, rev(seq_len(ncol(left))),], dims=2) == 3 |
  rowSums(right, dims=2) == 3
no.over.rle <- rle(colSums(no.overlap) == nrow(no.overlap))
overlap.size <- if(isTRUE(no.over.rle[['values']][1]))
  no.over.rle[['lengths']][1] else 0L

# combine and write png

combined <- array(0, dim=dim(left) * c(1,2,1) - c(0, overlap.size, 0))
combined[,seq_len(ncol(left)),] <- left
combined[,tail(seq_len(ncol(combined)), ncol(right)),] <-
  combined[,tail(seq_len(ncol(combined)), ncol(right)),] + right
png::writePNG(combined, 'persp.png')

```
[1]: https://en.wikipedia.org/wiki/Rotation_matrix#In_three_dimensions
[2]: https://www.brodieg.com/2018/11/23/is-your-matrix-running-slow-try-lists/

----
[^1]: Some 3D packages out there will blatantly lie to you by rotating the
      displayed axes along with the object, making it seem like the axes are
      rotating, but in reality the underlying axes are not rotating.  This lie
      made it particularly difficult for me to figure out why things were not
      rotating the way I thought they should.  I'm still pissed off about it.
[^2]: In reality we only *need* to do this for the polygons that are visible in
      the end result, but determining what is visible and not is non-trivial and
      we'll reserve that for a possible future low-probability-of-getting-made
      blog post.

